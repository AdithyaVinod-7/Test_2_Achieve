{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test2Achieve - Autograding.ipynb\n",
    "\n",
    "### Team 4: * Bharat Sharma * Adithya Vinod * Shanmukha Sai Penumatsa\n",
    "\n",
    "### Course: DAAN 897 - Deep Learning (Spring I, 2023)\n",
    "\n",
    "### Guide: Dr. Youkim Badr\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**PROBLEM STATEMENT:** In the world where CHATGPT exist, we want to give some powers to faculty by automating the process of evaluation and answer generation.\n",
    "\n",
    "Keywords:Descriptive Answer evaluation, Automatic Grading, Descriptive Examination System\n",
    "\n",
    "We have tried to solve this problem by breaking it down into two independent problem statements, namely:\n",
    "\n",
    "- Automated Answer Generation: We will be using pretrained models like Bert, Albert and Electra for answer generation tasks, where given a question or prompt, the model generates an answer. These models are trained on large amounts of text data and can learn to generate coherent and accurate response\n",
    "\n",
    "- Automated Grading: The answer and scores are first passed through the LSTM which are then passed through the multiple neural layers to train the model. The trained model will return a score for each answer based on historic grading\n",
    "\n",
    "In this python notebook we will be talking about the Automatic grading part of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-04-11T01:58:24.933254Z",
     "iopub.status.busy": "2021-04-11T01:58:24.932587Z",
     "iopub.status.idle": "2021-04-11T01:58:25.035256Z",
     "shell.execute_reply": "2021-04-11T01:58:25.034006Z"
    },
    "papermill": {
     "duration": 2.862097,
     "end_time": "2021-04-11T01:58:25.035366",
     "exception": false,
     "start_time": "2021-04-11T01:58:22.173269",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# importing all the necessary library\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score\n",
    "from sklearn.metrics import ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pre-processing\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models import Word2Vec\n",
    "# We have downloaded the below files and hence commented it out for not downloading it again\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# from tensorflow.keras.layers import LSTM\n",
    "# from tensorflow.keras.layers import Dropout\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.layers import Embedding\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To Utilize the computational resource (GPU) we have created a separate environment\n",
    "# this environment consist tensorflow gpu version\n",
    "import tensorflow as tf\n",
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Collection:\n",
    "\n",
    "We have used \"The Hewlett Foundation: Automated Essay Scoring\" dataset for building the neural network for answer grading\n",
    "\n",
    "It contains information like the essay id, essay which is the answer for our case and their respective grades.\n",
    "\n",
    "Each essay has in between 150-550 words in length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"test_set.tsv\",sep='\\t', encoding='ISO-8859-1')\n",
    "training_data = pd.read_csv(\"training_set_rel3.tsv\",sep='\\t', encoding='ISO-8859-1',\n",
    "                            usecols = ['essay_id', 'essay_set', 'essay','domain1_score'])\n",
    "valid_data = pd.read_csv(\"valid_set.tsv\",sep='\\t', encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration:\n",
    "\n",
    "We are exploring the data shape, rows and their first five values to get an idea of how the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0              8  \n",
       "1              9  \n",
       "2              7  \n",
       "3             10  \n",
       "4              8  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2383</td>\n",
       "      <td>1</td>\n",
       "      <td>I believe that computers have a positive effec...</td>\n",
       "      <td>2383</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2384</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1, I know some problems have came up...</td>\n",
       "      <td>2384</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2385</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear to whom it @MONTH1 concern, Computers are...</td>\n",
       "      <td>2385</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2386</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, @CAPS3 has come to my atte...</td>\n",
       "      <td>2386</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2387</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, I think that people have...</td>\n",
       "      <td>2387</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      2383          1  I believe that computers have a positive effec...   \n",
       "1      2384          1  Dear @CAPS1, I know some problems have came up...   \n",
       "2      2385          1  Dear to whom it @MONTH1 concern, Computers are...   \n",
       "3      2386          1  Dear @CAPS1 @CAPS2, @CAPS3 has come to my atte...   \n",
       "4      2387          1  Dear Local newspaper, I think that people have...   \n",
       "\n",
       "   domain1_predictionid  domain2_predictionid  \n",
       "0                  2383                   NaN  \n",
       "1                  2384                   NaN  \n",
       "2                  2385                   NaN  \n",
       "3                  2386                   NaN  \n",
       "4                  2387                   NaN  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_predictionid</th>\n",
       "      <th>domain2_predictionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1788</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @ORGANIZATION1, @CAPS1 more and more peop...</td>\n",
       "      <td>1788</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1789</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1 Time @CAPS1 me tell you what I...</td>\n",
       "      <td>1789</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1790</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local newspaper, Have you been spending a...</td>\n",
       "      <td>1790</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1791</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Readers, @CAPS1 you imagine how life woul...</td>\n",
       "      <td>1791</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1792</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear newspaper, I strongly believe that comput...</td>\n",
       "      <td>1792</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0      1788          1  Dear @ORGANIZATION1, @CAPS1 more and more peop...   \n",
       "1      1789          1  Dear @LOCATION1 Time @CAPS1 me tell you what I...   \n",
       "2      1790          1  Dear Local newspaper, Have you been spending a...   \n",
       "3      1791          1  Dear Readers, @CAPS1 you imagine how life woul...   \n",
       "4      1792          1  Dear newspaper, I strongly believe that comput...   \n",
       "\n",
       "   domain1_predictionid  domain2_predictionid  \n",
       "0                  1788                   NaN  \n",
       "1                  1789                   NaN  \n",
       "2                  1790                   NaN  \n",
       "3                  1791                   NaN  \n",
       "4                  1792                   NaN  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "- Dropping null values: Null values can be a issues so we have dropped the null values \n",
    "- Text Cleaning: Removing irrelevant information like punctuation, numbers, special charatecs and stop words from the text\n",
    "- Toeknization: Breaking down the text into smaller chunks\n",
    "\n",
    "We have created separate functions for performing all of this inside of the code, where function does the job in a abstract way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.dropna(axis=1,inplace=True)\n",
    "valid_data.dropna(axis=1,inplace=True)\n",
    "training_data.dropna(axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Splitting the dataset into X and y part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(       essay_id  essay_set                                              essay  \\\n",
       " 0             1          1  Dear local newspaper, I think effects computer...   \n",
       " 1             2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       " 2             3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       " 3             4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       " 4             5          1  Dear @LOCATION1, I know having computers has a...   \n",
       " ...         ...        ...                                                ...   \n",
       " 12971     21626          8   In most stories mothers and daughters are eit...   \n",
       " 12972     21628          8   I never understood the meaning laughter is th...   \n",
       " 12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       " 12974     21630          8                                 Trippin' on fen...   \n",
       " 12975     21633          8   Many people believe that laughter can improve...   \n",
       " \n",
       "        domain1_score  \n",
       " 0                  8  \n",
       " 1                  9  \n",
       " 2                  7  \n",
       " 3                 10  \n",
       " 4                  8  \n",
       " ...              ...  \n",
       " 12971             35  \n",
       " 12972             32  \n",
       " 12973             40  \n",
       " 12974             40  \n",
       " 12975             40  \n",
       " \n",
       " [12976 rows x 4 columns],\n",
       " 0         8\n",
       " 1         9\n",
       " 2         7\n",
       " 3        10\n",
       " 4         8\n",
       "          ..\n",
       " 12971    35\n",
       " 12972    32\n",
       " 12973    40\n",
       " 12974    40\n",
       " 12975    40\n",
       " Name: domain1_score, Length: 12976, dtype: int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data\n",
    "y = training_data['domain1_score']\n",
    "X = training_data.copy()\n",
    "X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wordlist_from_essay(essay_vector, remove_stopwords):\n",
    "    # Tokenizing the words and removing if there are any lables\n",
    "    essay_vector = re.sub(\"[^a-zA-Z]\", \" \", essay_v)\n",
    "    words = essay_vector.lower().split()\n",
    "    if remove_stopwords:\n",
    "        stop_words = set(stopwords.words(\"english\"))\n",
    "        words = [word for word in words if not word in stop_words]\n",
    "    return (words)\n",
    "\n",
    "def sentences_from_essay(essay_vector, remove_stopwords):\n",
    "    # function to tokenizing the sentences and calling the wordlist function\n",
    "    obj_tokenizer = nltk.data.load('tokenizers/punkt/english.pickle')\n",
    "    raw_sentences = obj_tokenizer.tokenize(essay_vector.strip())\n",
    "    sentences = []\n",
    "    for raw_sentence in raw_sentences:\n",
    "        if len(raw_sentence) > 0:\n",
    "            sentences.append(wordlist_from_essay(raw_sentence, remove_stopwords))\n",
    "    return sentences\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    # Creating Feactur Vector from model\n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float32\")\n",
    "    word_count = 0.\n",
    "    index2word_set = set(model.wv.index2word)\n",
    "    for word in words:\n",
    "        if word in index2word_set:\n",
    "            word_count += 1\n",
    "            feature_vector = np.add(feature_vector,model[word])        \n",
    "    feature_vector = np.divide(feature_vector,word_count)\n",
    "    return feature_vector\n",
    "\n",
    "def getAvgFeatureVecs(essays, model, num_features):\n",
    "    # Creating average of feature vector from model\n",
    "    counter = 0\n",
    "    essay_feature_vecs = np.zeros((len(essays),num_features),dtype=\"float32\")\n",
    "    for essay in essays:\n",
    "        essay_feature_vecs[counter] = makeFeatureVec(essay, model, num_features)\n",
    "        counter = counter + 1\n",
    "    return essay_feature_vecs\n",
    "\n",
    "def makeFeatureVec(words, model, num_features):\n",
    "    feature_vector = np.zeros((num_features,),dtype=\"float32\")\n",
    "    word_count = 0.\n",
    "    if isinstance(words, list):\n",
    "        words = \" \".join(words)\n",
    "    for word in words.split():\n",
    "        if word in model.wv:\n",
    "            word_count = word_count + 1.\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    if word_count > 0.:\n",
    "        feature_vector = np.divide(feature_vector, word_count)\n",
    "    return feature_vector\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Methodology:\n",
    "\n",
    "- Preprocessing and cleaning: After downloading the data, the biggest part of it was to pre process it, where we have used two different techniques, We have tokenized the paragraphs to Sentence based toeknizer to preserve the context and further we have tokenized into a wordlist based tokenizer\n",
    "\n",
    "- Vectorize: After the initial pre processing we created 3 separate functions for respective work\n",
    "  - Function makeFeatureVec: Created an average feature vector for a given list of words, using ta trained word2vec model\n",
    "  - Function getAvgFEatureVecs: Genereated a words vectors for a list of essays.\n",
    "  - Function makeFeatureVec: Creates an average feature vectir for a given string of words\n",
    "  \n",
    "**Keywords:** Natural language processing, Descriptive Answer processing, Descriptive Answer Evaluation, LSTM, Deep Learning\n",
    "\n",
    "- Model Selection: \n",
    "\n",
    "  - **LSTM (Long Short-Term Memory)** is a type of recurrent neural network (RNN) that is particularly effective in dealing with sequential data such as text. LSTM can capture the long-term dependencies and relationships between words in an essay, making it a suitable choice for grading written answers. It can also handle variable-length sequences, which is important for essays of different lengths.\n",
    "\n",
    "  - **Word2Vec** is a neural network-based technique to generate word embeddings, which are vector representations of words in a high-dimensional space. Word2Vec model is used for the answer grading process as it helps to represent words in a dense vector space that captures the context and meaning of the words. This enables the model to understand the relationships between words and identify the similarity between different words. By using Word2Vec model, the answer grading process can take into account not only the words used in the answer but also their meaning and context, allowing for more accurate and robust grading.\n",
    "\n",
    "- Model Specification: The model consists of two LSTM layers followed by a dropout layer and a dense layer with a single output node. For the metrics we have used MAR and accuracy and have created plots for checking the loss function and mae. For optimizer we have used RMSprop optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    \"\"\"\n",
    "    Defining the model architecture that will be used\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(300, dropout=0.4, recurrent_dropout=0.4, input_shape=[1, 300], return_sequences=True))\n",
    "    model.add(LSTM(64, recurrent_dropout=0.2))\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(1, activation='relu'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='rmsprop', metrics=['mae', 'accuracy'])\n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Fitting and Validation\n",
    "\n",
    "The code performs a 5-fold cross-validation on the given dataset using the KFold function from the scikit-learn library. For each fold, the code preprocesses the training and testing data, creates a Word2Vec model for the essays, generates average feature vectors for the essays using the model, reshapes the feature vectors, and trains an LSTM model using the feature vectors and corresponding labels.\n",
    "\n",
    "After training, the code makes predictions on the testing set, rounds the predictions to the nearest integer, and evaluates the model using the quadratic weighted kappa metric. The resulting kappa score for each fold is printed and saved in a list of results. Finally, the average kappa score is calculated over the five folds, representing the overall performance of the model. Additionally, the weights of the last model in the 5-fold cross-validation are saved for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "WARNING:tensorflow:Layer lstm_132 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_133 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_66\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_132 (LSTM)             (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_133 (LSTM)             (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_66 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_66 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 8s 19ms/step - loss: 80.1743 - mae: 5.2767 - accuracy: 0.1185 - val_loss: 63.8584 - val_mae: 4.7865 - val_accuracy: 0.1267\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 60.4686 - mae: 4.7840 - accuracy: 0.1125 - val_loss: 55.5005 - val_mae: 4.4148 - val_accuracy: 0.1059\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 54.1884 - mae: 4.5612 - accuracy: 0.1078 - val_loss: 50.7560 - val_mae: 4.2777 - val_accuracy: 0.1055\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 51.0381 - mae: 4.4648 - accuracy: 0.1017 - val_loss: 48.0368 - val_mae: 4.1620 - val_accuracy: 0.1025\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 49.2783 - mae: 4.3783 - accuracy: 0.1048 - val_loss: 45.4856 - val_mae: 4.0565 - val_accuracy: 0.1098\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 48.1762 - mae: 4.3218 - accuracy: 0.1109 - val_loss: 44.2953 - val_mae: 4.0812 - val_accuracy: 0.1167\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 46.3147 - mae: 4.2284 - accuracy: 0.1120 - val_loss: 41.4265 - val_mae: 3.7774 - val_accuracy: 0.1163\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 45.4218 - mae: 4.1662 - accuracy: 0.1163 - val_loss: 40.7659 - val_mae: 3.6724 - val_accuracy: 0.1202\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 43.7780 - mae: 4.0870 - accuracy: 0.1189 - val_loss: 38.3163 - val_mae: 3.5796 - val_accuracy: 0.1271\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 41.5941 - mae: 3.9528 - accuracy: 0.1222 - val_loss: 36.0356 - val_mae: 3.5233 - val_accuracy: 0.1283\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 40.4906 - mae: 3.8886 - accuracy: 0.1244 - val_loss: 34.3715 - val_mae: 3.3953 - val_accuracy: 0.1298\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 39.1524 - mae: 3.7992 - accuracy: 0.1269 - val_loss: 33.1630 - val_mae: 3.3383 - val_accuracy: 0.1290\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 37.7336 - mae: 3.7119 - accuracy: 0.1277 - val_loss: 31.6229 - val_mae: 3.2573 - val_accuracy: 0.1279\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 35.8135 - mae: 3.6368 - accuracy: 0.1274 - val_loss: 30.6470 - val_mae: 3.1605 - val_accuracy: 0.1275\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 34.2342 - mae: 3.5370 - accuracy: 0.1277 - val_loss: 28.6903 - val_mae: 3.1227 - val_accuracy: 0.1290\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 32.2161 - mae: 3.4392 - accuracy: 0.1264 - val_loss: 27.6989 - val_mae: 3.0830 - val_accuracy: 0.1279\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 31.5980 - mae: 3.4014 - accuracy: 0.1253 - val_loss: 27.7787 - val_mae: 3.1589 - val_accuracy: 0.1271\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 30.4979 - mae: 3.3592 - accuracy: 0.1261 - val_loss: 26.6352 - val_mae: 2.9656 - val_accuracy: 0.1290\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 29.5550 - mae: 3.2621 - accuracy: 0.1255 - val_loss: 25.5229 - val_mae: 2.9482 - val_accuracy: 0.1287\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 29.0577 - mae: 3.2651 - accuracy: 0.1251 - val_loss: 24.8835 - val_mae: 2.9014 - val_accuracy: 0.1290\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 27.5158 - mae: 3.1586 - accuracy: 0.1240 - val_loss: 24.5208 - val_mae: 2.9224 - val_accuracy: 0.1287\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 27.6800 - mae: 3.1870 - accuracy: 0.1254 - val_loss: 23.4758 - val_mae: 2.8468 - val_accuracy: 0.1290\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 26.8208 - mae: 3.1155 - accuracy: 0.1237 - val_loss: 23.5054 - val_mae: 2.8217 - val_accuracy: 0.1294\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 25.8647 - mae: 3.0615 - accuracy: 0.1250 - val_loss: 23.6077 - val_mae: 2.8926 - val_accuracy: 0.1283\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 26.5593 - mae: 3.0807 - accuracy: 0.1262 - val_loss: 22.6725 - val_mae: 2.7453 - val_accuracy: 0.1287\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.3304 - mae: 2.9788 - accuracy: 0.1246 - val_loss: 21.9658 - val_mae: 2.6952 - val_accuracy: 0.1287\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.3621 - mae: 2.9625 - accuracy: 0.1256 - val_loss: 21.5204 - val_mae: 2.7155 - val_accuracy: 0.1290\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.4061 - mae: 2.9631 - accuracy: 0.1247 - val_loss: 21.5965 - val_mae: 2.7191 - val_accuracy: 0.1294\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 24.4253 - mae: 2.9398 - accuracy: 0.1264 - val_loss: 20.6896 - val_mae: 2.6358 - val_accuracy: 0.1302\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 23.5249 - mae: 2.8772 - accuracy: 0.1263 - val_loss: 21.2814 - val_mae: 2.6312 - val_accuracy: 0.1306\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 22.9119 - mae: 2.8650 - accuracy: 0.1250 - val_loss: 19.6466 - val_mae: 2.5830 - val_accuracy: 0.1314\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 22.9528 - mae: 2.8627 - accuracy: 0.1260 - val_loss: 19.5827 - val_mae: 2.5591 - val_accuracy: 0.1317\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.0485 - mae: 2.8223 - accuracy: 0.1236 - val_loss: 19.3904 - val_mae: 2.5614 - val_accuracy: 0.1314\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 22.2672 - mae: 2.8029 - accuracy: 0.1264 - val_loss: 19.0878 - val_mae: 2.6020 - val_accuracy: 0.1321\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.7438 - mae: 2.7918 - accuracy: 0.1253 - val_loss: 18.5508 - val_mae: 2.5296 - val_accuracy: 0.1317\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.8410 - mae: 2.7746 - accuracy: 0.1250 - val_loss: 18.2194 - val_mae: 2.4712 - val_accuracy: 0.1325\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 20.7488 - mae: 2.7158 - accuracy: 0.1257 - val_loss: 18.3244 - val_mae: 2.4530 - val_accuracy: 0.1317\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 21.3284 - mae: 2.7256 - accuracy: 0.1259 - val_loss: 17.7260 - val_mae: 2.4533 - val_accuracy: 0.1306\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 20.9203 - mae: 2.7227 - accuracy: 0.1257 - val_loss: 17.7602 - val_mae: 2.5022 - val_accuracy: 0.1317\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.2461 - mae: 2.6702 - accuracy: 0.1264 - val_loss: 18.4412 - val_mae: 2.4565 - val_accuracy: 0.1314\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.9551 - mae: 2.6661 - accuracy: 0.1262 - val_loss: 16.9487 - val_mae: 2.4033 - val_accuracy: 0.1329\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.6872 - mae: 2.6395 - accuracy: 0.1247 - val_loss: 17.0943 - val_mae: 2.4285 - val_accuracy: 0.1317\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 19.4098 - mae: 2.6437 - accuracy: 0.1257 - val_loss: 16.2435 - val_mae: 2.3891 - val_accuracy: 0.1333\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 19.8279 - mae: 2.6414 - accuracy: 0.1266 - val_loss: 17.2552 - val_mae: 2.4649 - val_accuracy: 0.1341\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 19.1063 - mae: 2.6098 - accuracy: 0.1261 - val_loss: 16.3572 - val_mae: 2.3822 - val_accuracy: 0.1333\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 19.2609 - mae: 2.5943 - accuracy: 0.1265 - val_loss: 16.1925 - val_mae: 2.3603 - val_accuracy: 0.1341\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.5310 - mae: 2.5565 - accuracy: 0.1271 - val_loss: 16.1708 - val_mae: 2.3388 - val_accuracy: 0.1325\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 19.2821 - mae: 2.5903 - accuracy: 0.1279 - val_loss: 16.2141 - val_mae: 2.3397 - val_accuracy: 0.1333\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.5808 - mae: 2.5514 - accuracy: 0.1274 - val_loss: 15.4675 - val_mae: 2.3047 - val_accuracy: 0.1329\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 18.5627 - mae: 2.5526 - accuracy: 0.1272 - val_loss: 15.5575 - val_mae: 2.2889 - val_accuracy: 0.1333\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.0126 - mae: 2.5272 - accuracy: 0.1250 - val_loss: 15.1170 - val_mae: 2.2736 - val_accuracy: 0.1325\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.9208 - mae: 2.5134 - accuracy: 0.1275 - val_loss: 15.4018 - val_mae: 2.3266 - val_accuracy: 0.1333\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.9969 - mae: 2.5218 - accuracy: 0.1277 - val_loss: 15.2030 - val_mae: 2.2750 - val_accuracy: 0.1325\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.5628 - mae: 2.4898 - accuracy: 0.1267 - val_loss: 15.3366 - val_mae: 2.2888 - val_accuracy: 0.1333\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.7923 - mae: 2.4876 - accuracy: 0.1268 - val_loss: 15.9188 - val_mae: 2.2789 - val_accuracy: 0.1314\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.0328 - mae: 2.4631 - accuracy: 0.1253 - val_loss: 14.8170 - val_mae: 2.2505 - val_accuracy: 0.1329\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 17.6786 - mae: 2.5073 - accuracy: 0.1262 - val_loss: 14.9233 - val_mae: 2.2350 - val_accuracy: 0.1317\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.1316 - mae: 2.4616 - accuracy: 0.1258 - val_loss: 14.6990 - val_mae: 2.2075 - val_accuracy: 0.1317\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.4700 - mae: 2.4258 - accuracy: 0.1264 - val_loss: 14.7951 - val_mae: 2.2249 - val_accuracy: 0.1302\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.5762 - mae: 2.4214 - accuracy: 0.1261 - val_loss: 14.4182 - val_mae: 2.2072 - val_accuracy: 0.1298\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.5803 - mae: 2.4366 - accuracy: 0.1258 - val_loss: 14.5028 - val_mae: 2.2268 - val_accuracy: 0.1325\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.8095 - mae: 2.4164 - accuracy: 0.1269 - val_loss: 14.7349 - val_mae: 2.2535 - val_accuracy: 0.1321\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.2591 - mae: 2.4031 - accuracy: 0.1273 - val_loss: 14.8484 - val_mae: 2.2077 - val_accuracy: 0.1314\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.3689 - mae: 2.4145 - accuracy: 0.1257 - val_loss: 14.1872 - val_mae: 2.1896 - val_accuracy: 0.1310\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.5762 - mae: 2.4134 - accuracy: 0.1276 - val_loss: 14.0781 - val_mae: 2.2019 - val_accuracy: 0.1321\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.8969 - mae: 2.3882 - accuracy: 0.1253 - val_loss: 14.1151 - val_mae: 2.1493 - val_accuracy: 0.1306\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.1446 - mae: 2.3384 - accuracy: 0.1270 - val_loss: 14.2377 - val_mae: 2.1680 - val_accuracy: 0.1321\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 15.4293 - mae: 2.3448 - accuracy: 0.1253 - val_loss: 14.1051 - val_mae: 2.1708 - val_accuracy: 0.1302\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.4490 - mae: 2.3488 - accuracy: 0.1271 - val_loss: 13.7967 - val_mae: 2.1473 - val_accuracy: 0.1302\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 15.2430 - mae: 2.3525 - accuracy: 0.1281 - val_loss: 13.9054 - val_mae: 2.1460 - val_accuracy: 0.1294\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.8775 - mae: 2.3347 - accuracy: 0.1266 - val_loss: 14.6617 - val_mae: 2.1942 - val_accuracy: 0.1294\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.9230 - mae: 2.3297 - accuracy: 0.1280 - val_loss: 14.3665 - val_mae: 2.1477 - val_accuracy: 0.1294\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.9891 - mae: 2.3136 - accuracy: 0.1276 - val_loss: 13.7888 - val_mae: 2.1577 - val_accuracy: 0.1325\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.7068 - mae: 2.2845 - accuracy: 0.1278 - val_loss: 13.4757 - val_mae: 2.1301 - val_accuracy: 0.1314\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.5491 - mae: 2.2881 - accuracy: 0.1272 - val_loss: 13.6540 - val_mae: 2.1465 - val_accuracy: 0.1302\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.7277 - mae: 2.3006 - accuracy: 0.1253 - val_loss: 13.3948 - val_mae: 2.1094 - val_accuracy: 0.1310\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 15.3169 - mae: 2.3163 - accuracy: 0.1261 - val_loss: 13.5640 - val_mae: 2.1098 - val_accuracy: 0.1302\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.5064 - mae: 2.2760 - accuracy: 0.1268 - val_loss: 13.3722 - val_mae: 2.1178 - val_accuracy: 0.1314\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.4567 - mae: 2.2679 - accuracy: 0.1267 - val_loss: 13.4067 - val_mae: 2.1311 - val_accuracy: 0.1314\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.3326 - mae: 2.2845 - accuracy: 0.1274 - val_loss: 13.4810 - val_mae: 2.1059 - val_accuracy: 0.1302\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 13.9582 - mae: 2.2468 - accuracy: 0.1254 - val_loss: 13.4856 - val_mae: 2.1183 - val_accuracy: 0.1314\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 14.2511 - mae: 2.2612 - accuracy: 0.1262 - val_loss: 13.8156 - val_mae: 2.0988 - val_accuracy: 0.1302\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.5219 - mae: 2.2731 - accuracy: 0.1269 - val_loss: 14.3111 - val_mae: 2.1704 - val_accuracy: 0.1310\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 14.4825 - mae: 2.2705 - accuracy: 0.1285 - val_loss: 13.4381 - val_mae: 2.0823 - val_accuracy: 0.1298\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 13.7236 - mae: 2.2415 - accuracy: 0.1246 - val_loss: 14.2702 - val_mae: 2.1148 - val_accuracy: 0.1287\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 14.1570 - mae: 2.2436 - accuracy: 0.1265 - val_loss: 13.0273 - val_mae: 2.0863 - val_accuracy: 0.1314\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.9876 - mae: 2.2337 - accuracy: 0.1272 - val_loss: 13.3391 - val_mae: 2.1223 - val_accuracy: 0.1314\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.2795 - mae: 2.1860 - accuracy: 0.1280 - val_loss: 13.5246 - val_mae: 2.0790 - val_accuracy: 0.1306\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.6824 - mae: 2.2232 - accuracy: 0.1275 - val_loss: 13.2096 - val_mae: 2.1210 - val_accuracy: 0.1302\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.9541 - mae: 2.2247 - accuracy: 0.1272 - val_loss: 12.9268 - val_mae: 2.0452 - val_accuracy: 0.1306\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 13.6954 - mae: 2.2045 - accuracy: 0.1263 - val_loss: 13.3819 - val_mae: 2.1102 - val_accuracy: 0.1317\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.3974 - mae: 2.1891 - accuracy: 0.1264 - val_loss: 13.0478 - val_mae: 2.0753 - val_accuracy: 0.1298\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.7180 - mae: 2.2143 - accuracy: 0.1272 - val_loss: 12.9107 - val_mae: 2.0751 - val_accuracy: 0.1314\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 13.4684 - mae: 2.2035 - accuracy: 0.1270 - val_loss: 12.8201 - val_mae: 2.0584 - val_accuracy: 0.1314\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 13.4813 - mae: 2.2090 - accuracy: 0.1266 - val_loss: 12.7287 - val_mae: 2.0410 - val_accuracy: 0.1314\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.3348 - mae: 2.1982 - accuracy: 0.1273 - val_loss: 12.9706 - val_mae: 2.0258 - val_accuracy: 0.1298\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 13.4036 - mae: 2.1868 - accuracy: 0.1273 - val_loss: 13.5539 - val_mae: 2.0657 - val_accuracy: 0.1294\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 13.1858 - mae: 2.1711 - accuracy: 0.1275 - val_loss: 13.3872 - val_mae: 2.0506 - val_accuracy: 0.1306\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 12.8958 - mae: 2.1665 - accuracy: 0.1282 - val_loss: 13.5068 - val_mae: 2.0751 - val_accuracy: 0.1306\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 12.7269 - mae: 2.1368 - accuracy: 0.1278 - val_loss: 14.8930 - val_mae: 2.2053 - val_accuracy: 0.1325\n",
      "Kappa Score: 0.9072702144438441\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "WARNING:tensorflow:Layer lstm_134 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_135 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_67\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_134 (LSTM)             (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_135 (LSTM)             (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_67 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_67 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 9s 23ms/step - loss: 80.2351 - mae: 5.2415 - accuracy: 0.1193 - val_loss: 66.9461 - val_mae: 4.9570 - val_accuracy: 0.1237\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 59.5359 - mae: 4.7188 - accuracy: 0.1151 - val_loss: 57.1409 - val_mae: 4.6551 - val_accuracy: 0.1114\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 53.4317 - mae: 4.5458 - accuracy: 0.1063 - val_loss: 52.1870 - val_mae: 4.4696 - val_accuracy: 0.1075\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 50.5957 - mae: 4.4641 - accuracy: 0.1069 - val_loss: 49.2724 - val_mae: 4.2998 - val_accuracy: 0.1133\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 48.3462 - mae: 4.3562 - accuracy: 0.1085 - val_loss: 46.4048 - val_mae: 4.0675 - val_accuracy: 0.1160\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 46.9047 - mae: 4.2588 - accuracy: 0.1121 - val_loss: 44.6186 - val_mae: 3.9822 - val_accuracy: 0.1175\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 46.2874 - mae: 4.2174 - accuracy: 0.1134 - val_loss: 43.2757 - val_mae: 3.9535 - val_accuracy: 0.1171\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 45.0054 - mae: 4.1413 - accuracy: 0.1194 - val_loss: 41.4730 - val_mae: 3.7312 - val_accuracy: 0.1187\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 42.3773 - mae: 3.9963 - accuracy: 0.1207 - val_loss: 38.7310 - val_mae: 3.6600 - val_accuracy: 0.1195\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 41.2231 - mae: 3.9269 - accuracy: 0.1234 - val_loss: 36.5211 - val_mae: 3.5787 - val_accuracy: 0.1210\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 39.0034 - mae: 3.8160 - accuracy: 0.1259 - val_loss: 34.2675 - val_mae: 3.4915 - val_accuracy: 0.1206\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 38.0198 - mae: 3.7599 - accuracy: 0.1272 - val_loss: 34.1000 - val_mae: 3.4010 - val_accuracy: 0.1202\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 36.4910 - mae: 3.6735 - accuracy: 0.1274 - val_loss: 32.3687 - val_mae: 3.3342 - val_accuracy: 0.1202\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 35.2193 - mae: 3.5848 - accuracy: 0.1282 - val_loss: 30.7569 - val_mae: 3.2714 - val_accuracy: 0.1198\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 34.0561 - mae: 3.5153 - accuracy: 0.1271 - val_loss: 31.1377 - val_mae: 3.2255 - val_accuracy: 0.1214\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 33.0170 - mae: 3.4679 - accuracy: 0.1283 - val_loss: 29.0918 - val_mae: 3.1367 - val_accuracy: 0.1218\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 31.4863 - mae: 3.4043 - accuracy: 0.1284 - val_loss: 27.5042 - val_mae: 3.1676 - val_accuracy: 0.1214\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 30.6529 - mae: 3.3192 - accuracy: 0.1286 - val_loss: 26.4791 - val_mae: 3.0759 - val_accuracy: 0.1222\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 30.3045 - mae: 3.3089 - accuracy: 0.1284 - val_loss: 25.8842 - val_mae: 3.0130 - val_accuracy: 0.1206\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 28.5912 - mae: 3.2276 - accuracy: 0.1285 - val_loss: 24.7524 - val_mae: 2.9602 - val_accuracy: 0.1191\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 27.9060 - mae: 3.1759 - accuracy: 0.1279 - val_loss: 24.5920 - val_mae: 2.9112 - val_accuracy: 0.1198\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 27.2157 - mae: 3.1387 - accuracy: 0.1276 - val_loss: 23.3141 - val_mae: 2.8932 - val_accuracy: 0.1214\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 27.1239 - mae: 3.1343 - accuracy: 0.1268 - val_loss: 22.9434 - val_mae: 2.8616 - val_accuracy: 0.1210\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 26.4086 - mae: 3.0822 - accuracy: 0.1274 - val_loss: 22.7718 - val_mae: 2.8364 - val_accuracy: 0.1214\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 26.4051 - mae: 3.0801 - accuracy: 0.1269 - val_loss: 22.3198 - val_mae: 2.8705 - val_accuracy: 0.1206\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 25.6492 - mae: 3.0306 - accuracy: 0.1266 - val_loss: 21.7923 - val_mae: 2.8587 - val_accuracy: 0.1202\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 25.6196 - mae: 3.0302 - accuracy: 0.1278 - val_loss: 21.7269 - val_mae: 2.7660 - val_accuracy: 0.1202\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.5647 - mae: 2.9760 - accuracy: 0.1266 - val_loss: 20.6889 - val_mae: 2.7597 - val_accuracy: 0.1202\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 24.4195 - mae: 2.9632 - accuracy: 0.1267 - val_loss: 20.5747 - val_mae: 2.7190 - val_accuracy: 0.1202\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 23.7078 - mae: 2.9192 - accuracy: 0.1262 - val_loss: 19.9397 - val_mae: 2.7082 - val_accuracy: 0.1202\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 23.3646 - mae: 2.9056 - accuracy: 0.1268 - val_loss: 19.8090 - val_mae: 2.7401 - val_accuracy: 0.1210\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.5824 - mae: 2.8585 - accuracy: 0.1272 - val_loss: 19.6705 - val_mae: 2.7514 - val_accuracy: 0.1198\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.5397 - mae: 2.8574 - accuracy: 0.1275 - val_loss: 18.9202 - val_mae: 2.6189 - val_accuracy: 0.1202\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.6797 - mae: 2.8470 - accuracy: 0.1276 - val_loss: 18.8651 - val_mae: 2.6116 - val_accuracy: 0.1198\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.8393 - mae: 2.8011 - accuracy: 0.1280 - val_loss: 18.7100 - val_mae: 2.5907 - val_accuracy: 0.1206\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 21.1945 - mae: 2.7580 - accuracy: 0.1277 - val_loss: 18.1490 - val_mae: 2.5537 - val_accuracy: 0.1202\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.3504 - mae: 2.7866 - accuracy: 0.1270 - val_loss: 17.6750 - val_mae: 2.5741 - val_accuracy: 0.1210\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.9444 - mae: 2.7441 - accuracy: 0.1276 - val_loss: 17.4776 - val_mae: 2.5559 - val_accuracy: 0.1206\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.4211 - mae: 2.7091 - accuracy: 0.1270 - val_loss: 17.4323 - val_mae: 2.5128 - val_accuracy: 0.1206\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.5785 - mae: 2.6997 - accuracy: 0.1280 - val_loss: 17.0384 - val_mae: 2.4680 - val_accuracy: 0.1206\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.0763 - mae: 2.6889 - accuracy: 0.1268 - val_loss: 16.8350 - val_mae: 2.5304 - val_accuracy: 0.1218\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.8619 - mae: 2.6587 - accuracy: 0.1277 - val_loss: 18.4955 - val_mae: 2.4882 - val_accuracy: 0.1214\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.9051 - mae: 2.6584 - accuracy: 0.1279 - val_loss: 17.7173 - val_mae: 2.6371 - val_accuracy: 0.1225\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 19.2223 - mae: 2.6216 - accuracy: 0.1272 - val_loss: 16.8713 - val_mae: 2.5596 - val_accuracy: 0.1222\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.3490 - mae: 2.6261 - accuracy: 0.1268 - val_loss: 16.6351 - val_mae: 2.5362 - val_accuracy: 0.1218\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 19.7748 - mae: 2.6475 - accuracy: 0.1256 - val_loss: 15.7675 - val_mae: 2.4322 - val_accuracy: 0.1210\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.4776 - mae: 2.6199 - accuracy: 0.1275 - val_loss: 15.9949 - val_mae: 2.4261 - val_accuracy: 0.1218\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.5418 - mae: 2.5422 - accuracy: 0.1267 - val_loss: 15.9296 - val_mae: 2.3689 - val_accuracy: 0.1222\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.6868 - mae: 2.5494 - accuracy: 0.1277 - val_loss: 15.3886 - val_mae: 2.3653 - val_accuracy: 0.1218\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.1665 - mae: 2.5347 - accuracy: 0.1273 - val_loss: 15.0705 - val_mae: 2.3687 - val_accuracy: 0.1218\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.9309 - mae: 2.5173 - accuracy: 0.1271 - val_loss: 15.8489 - val_mae: 2.4719 - val_accuracy: 0.1222\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.5967 - mae: 2.4977 - accuracy: 0.1272 - val_loss: 14.8902 - val_mae: 2.3708 - val_accuracy: 0.1218\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 18.5248 - mae: 2.5338 - accuracy: 0.1280 - val_loss: 16.0241 - val_mae: 2.3081 - val_accuracy: 0.1206\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 18.2278 - mae: 2.5171 - accuracy: 0.1289 - val_loss: 15.4843 - val_mae: 2.3082 - val_accuracy: 0.1210\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 17.1971 - mae: 2.4880 - accuracy: 0.1283 - val_loss: 14.7143 - val_mae: 2.3858 - val_accuracy: 0.1218\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.1102 - mae: 2.5217 - accuracy: 0.1284 - val_loss: 14.5513 - val_mae: 2.2813 - val_accuracy: 0.1202\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 2s 14ms/step - loss: 17.3596 - mae: 2.4886 - accuracy: 0.1285 - val_loss: 15.9275 - val_mae: 2.2980 - val_accuracy: 0.1229\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 2s 14ms/step - loss: 17.6408 - mae: 2.4819 - accuracy: 0.1280 - val_loss: 14.6539 - val_mae: 2.4065 - val_accuracy: 0.1214\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 17.1536 - mae: 2.4686 - accuracy: 0.1268 - val_loss: 14.3323 - val_mae: 2.2565 - val_accuracy: 0.1202\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.6012 - mae: 2.4909 - accuracy: 0.1282 - val_loss: 14.7606 - val_mae: 2.2546 - val_accuracy: 0.1195\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.8234 - mae: 2.4526 - accuracy: 0.1286 - val_loss: 13.8465 - val_mae: 2.2387 - val_accuracy: 0.1210\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.3161 - mae: 2.4250 - accuracy: 0.1275 - val_loss: 16.4755 - val_mae: 2.4815 - val_accuracy: 0.1218\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.8890 - mae: 2.4321 - accuracy: 0.1281 - val_loss: 13.6416 - val_mae: 2.2589 - val_accuracy: 0.1214\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 16.6729 - mae: 2.4320 - accuracy: 0.1281 - val_loss: 13.2350 - val_mae: 2.2208 - val_accuracy: 0.1183\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.9076 - mae: 2.3699 - accuracy: 0.1288 - val_loss: 13.0853 - val_mae: 2.2099 - val_accuracy: 0.1191\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.1137 - mae: 2.3989 - accuracy: 0.1281 - val_loss: 13.1184 - val_mae: 2.2745 - val_accuracy: 0.1214\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.1077 - mae: 2.3891 - accuracy: 0.1271 - val_loss: 13.2632 - val_mae: 2.1949 - val_accuracy: 0.1210\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.9875 - mae: 2.3938 - accuracy: 0.1268 - val_loss: 12.6537 - val_mae: 2.2011 - val_accuracy: 0.1214\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 16.2145 - mae: 2.3924 - accuracy: 0.1277 - val_loss: 12.6875 - val_mae: 2.1820 - val_accuracy: 0.1214\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.9064 - mae: 2.3834 - accuracy: 0.1273 - val_loss: 12.5705 - val_mae: 2.1838 - val_accuracy: 0.1214\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.6565 - mae: 2.3730 - accuracy: 0.1276 - val_loss: 12.5596 - val_mae: 2.1565 - val_accuracy: 0.1214\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.3395 - mae: 2.3493 - accuracy: 0.1277 - val_loss: 12.5302 - val_mae: 2.1925 - val_accuracy: 0.1187\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.1951 - mae: 2.3446 - accuracy: 0.1276 - val_loss: 13.4306 - val_mae: 2.2724 - val_accuracy: 0.1218\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 15.5302 - mae: 2.3371 - accuracy: 0.1279 - val_loss: 12.6444 - val_mae: 2.1506 - val_accuracy: 0.1198\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.7473 - mae: 2.3461 - accuracy: 0.1286 - val_loss: 12.7233 - val_mae: 2.1688 - val_accuracy: 0.1218\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.2207 - mae: 2.3371 - accuracy: 0.1288 - val_loss: 12.5335 - val_mae: 2.1539 - val_accuracy: 0.1225\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.0966 - mae: 2.3268 - accuracy: 0.1273 - val_loss: 12.4295 - val_mae: 2.1601 - val_accuracy: 0.1237\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.1333 - mae: 2.3126 - accuracy: 0.1280 - val_loss: 14.1271 - val_mae: 2.2016 - val_accuracy: 0.1191\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 15.4283 - mae: 2.3329 - accuracy: 0.1289 - val_loss: 12.2438 - val_mae: 2.1400 - val_accuracy: 0.1210\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 14.6490 - mae: 2.2923 - accuracy: 0.1272 - val_loss: 13.5148 - val_mae: 2.3371 - val_accuracy: 0.1214\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.3908 - mae: 2.2895 - accuracy: 0.1287 - val_loss: 11.9263 - val_mae: 2.1362 - val_accuracy: 0.1233\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.3816 - mae: 2.2835 - accuracy: 0.1281 - val_loss: 12.1678 - val_mae: 2.1485 - val_accuracy: 0.1229\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 14.7049 - mae: 2.2923 - accuracy: 0.1279 - val_loss: 11.8835 - val_mae: 2.0944 - val_accuracy: 0.1233\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 14.6013 - mae: 2.2804 - accuracy: 0.1282 - val_loss: 13.7129 - val_mae: 2.3144 - val_accuracy: 0.1233\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.4290 - mae: 2.2972 - accuracy: 0.1293 - val_loss: 12.4362 - val_mae: 2.0856 - val_accuracy: 0.1218\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.4769 - mae: 2.2719 - accuracy: 0.1278 - val_loss: 12.4040 - val_mae: 2.1029 - val_accuracy: 0.1210\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.2469 - mae: 2.2596 - accuracy: 0.1296 - val_loss: 12.3602 - val_mae: 2.2151 - val_accuracy: 0.1237\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 14.4339 - mae: 2.2718 - accuracy: 0.1280 - val_loss: 11.9864 - val_mae: 2.1813 - val_accuracy: 0.1237\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.3167 - mae: 2.2642 - accuracy: 0.1294 - val_loss: 11.4417 - val_mae: 2.1063 - val_accuracy: 0.1241\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.3816 - mae: 2.2590 - accuracy: 0.1292 - val_loss: 11.4405 - val_mae: 2.0994 - val_accuracy: 0.1241\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.2696 - mae: 2.2598 - accuracy: 0.1294 - val_loss: 11.7330 - val_mae: 2.0514 - val_accuracy: 0.1237\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.8941 - mae: 2.2279 - accuracy: 0.1294 - val_loss: 11.4256 - val_mae: 2.0989 - val_accuracy: 0.1241\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.0883 - mae: 2.2526 - accuracy: 0.1286 - val_loss: 11.3671 - val_mae: 2.0775 - val_accuracy: 0.1245\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.6814 - mae: 2.2239 - accuracy: 0.1290 - val_loss: 11.2438 - val_mae: 2.0870 - val_accuracy: 0.1241\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.5962 - mae: 2.1971 - accuracy: 0.1299 - val_loss: 11.4473 - val_mae: 2.0825 - val_accuracy: 0.1222\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 13.5591 - mae: 2.2148 - accuracy: 0.1277 - val_loss: 11.6136 - val_mae: 2.0371 - val_accuracy: 0.1222\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.8552 - mae: 2.2209 - accuracy: 0.1289 - val_loss: 11.3621 - val_mae: 2.0698 - val_accuracy: 0.1237\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.5482 - mae: 2.1989 - accuracy: 0.1288 - val_loss: 11.3495 - val_mae: 2.0293 - val_accuracy: 0.1222\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.7616 - mae: 2.2121 - accuracy: 0.1296 - val_loss: 11.2348 - val_mae: 2.0430 - val_accuracy: 0.1218\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.5277 - mae: 2.2083 - accuracy: 0.1283 - val_loss: 11.3142 - val_mae: 2.0708 - val_accuracy: 0.1214\n",
      "Kappa Score: 0.9283517592144572\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "WARNING:tensorflow:Layer lstm_136 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_137 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_68\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_136 (LSTM)             (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_137 (LSTM)             (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_68 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_68 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 10s 20ms/step - loss: 80.6433 - mae: 5.2236 - accuracy: 0.1238 - val_loss: 60.6387 - val_mae: 4.5901 - val_accuracy: 0.1249\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 62.3387 - mae: 4.7984 - accuracy: 0.1119 - val_loss: 51.6029 - val_mae: 4.2340 - val_accuracy: 0.1091\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 54.4309 - mae: 4.5226 - accuracy: 0.1016 - val_loss: 44.2940 - val_mae: 4.0285 - val_accuracy: 0.1002\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 50.1330 - mae: 4.4084 - accuracy: 0.0982 - val_loss: 40.5258 - val_mae: 3.9820 - val_accuracy: 0.0960\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 48.5324 - mae: 4.4020 - accuracy: 0.0980 - val_loss: 38.9576 - val_mae: 3.8427 - val_accuracy: 0.0975\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 46.6680 - mae: 4.3016 - accuracy: 0.1007 - val_loss: 36.4002 - val_mae: 3.6720 - val_accuracy: 0.1033\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 44.3643 - mae: 4.1582 - accuracy: 0.1038 - val_loss: 34.6828 - val_mae: 3.5949 - val_accuracy: 0.1056\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 43.2074 - mae: 4.1163 - accuracy: 0.1063 - val_loss: 33.0242 - val_mae: 3.5049 - val_accuracy: 0.1141\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 40.9464 - mae: 3.9813 - accuracy: 0.1127 - val_loss: 31.7852 - val_mae: 3.4227 - val_accuracy: 0.1191\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 39.7095 - mae: 3.8916 - accuracy: 0.1177 - val_loss: 30.9412 - val_mae: 3.3367 - val_accuracy: 0.1187\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 38.5763 - mae: 3.8073 - accuracy: 0.1222 - val_loss: 30.8196 - val_mae: 3.2881 - val_accuracy: 0.1218\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 37.2615 - mae: 3.7399 - accuracy: 0.1249 - val_loss: 29.6556 - val_mae: 3.2147 - val_accuracy: 0.1264\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 35.8618 - mae: 3.6371 - accuracy: 0.1258 - val_loss: 27.8386 - val_mae: 3.1514 - val_accuracy: 0.1245\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 34.6797 - mae: 3.5510 - accuracy: 0.1271 - val_loss: 26.6613 - val_mae: 3.1092 - val_accuracy: 0.1287\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 33.9781 - mae: 3.5081 - accuracy: 0.1291 - val_loss: 26.8243 - val_mae: 3.0238 - val_accuracy: 0.1276\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 32.0608 - mae: 3.4125 - accuracy: 0.1278 - val_loss: 26.5470 - val_mae: 2.9691 - val_accuracy: 0.1279\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 31.0203 - mae: 3.3541 - accuracy: 0.1276 - val_loss: 25.7197 - val_mae: 2.9391 - val_accuracy: 0.1279\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 29.8351 - mae: 3.2856 - accuracy: 0.1257 - val_loss: 23.1311 - val_mae: 2.9585 - val_accuracy: 0.1279\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 28.9255 - mae: 3.2570 - accuracy: 0.1263 - val_loss: 24.5855 - val_mae: 2.8746 - val_accuracy: 0.1279\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 28.4747 - mae: 3.2102 - accuracy: 0.1266 - val_loss: 23.0966 - val_mae: 2.8232 - val_accuracy: 0.1272\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 27.6656 - mae: 3.1668 - accuracy: 0.1264 - val_loss: 22.3229 - val_mae: 2.8317 - val_accuracy: 0.1272\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 27.2801 - mae: 3.1454 - accuracy: 0.1259 - val_loss: 21.3239 - val_mae: 2.7769 - val_accuracy: 0.1268\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 26.6373 - mae: 3.1012 - accuracy: 0.1254 - val_loss: 21.3246 - val_mae: 2.7438 - val_accuracy: 0.1283\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 25.2522 - mae: 3.0074 - accuracy: 0.1266 - val_loss: 20.8317 - val_mae: 2.7193 - val_accuracy: 0.1283\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.0558 - mae: 2.9908 - accuracy: 0.1251 - val_loss: 20.2482 - val_mae: 2.7237 - val_accuracy: 0.1279\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 24.9782 - mae: 3.0132 - accuracy: 0.1249 - val_loss: 19.9390 - val_mae: 2.7477 - val_accuracy: 0.1276\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 25.1859 - mae: 3.0168 - accuracy: 0.1265 - val_loss: 20.5275 - val_mae: 2.6683 - val_accuracy: 0.1291\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 2s 14ms/step - loss: 24.1843 - mae: 2.9209 - accuracy: 0.1265 - val_loss: 19.0701 - val_mae: 2.6292 - val_accuracy: 0.1291\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 23.4065 - mae: 2.9036 - accuracy: 0.1274 - val_loss: 21.3699 - val_mae: 2.6846 - val_accuracy: 0.1252\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 23.9878 - mae: 2.9194 - accuracy: 0.1281 - val_loss: 18.3994 - val_mae: 2.6216 - val_accuracy: 0.1283\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 22.6315 - mae: 2.8522 - accuracy: 0.1275 - val_loss: 18.4339 - val_mae: 2.5804 - val_accuracy: 0.1279\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.3038 - mae: 2.8267 - accuracy: 0.1268 - val_loss: 18.3238 - val_mae: 2.5415 - val_accuracy: 0.1260\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 21.9529 - mae: 2.7994 - accuracy: 0.1278 - val_loss: 18.6205 - val_mae: 2.6560 - val_accuracy: 0.1283\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 22.8353 - mae: 2.8295 - accuracy: 0.1277 - val_loss: 17.5386 - val_mae: 2.5458 - val_accuracy: 0.1276\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.6723 - mae: 2.7636 - accuracy: 0.1290 - val_loss: 17.8754 - val_mae: 2.5307 - val_accuracy: 0.1276\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.8416 - mae: 2.7828 - accuracy: 0.1272 - val_loss: 17.2038 - val_mae: 2.4755 - val_accuracy: 0.1291\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.1781 - mae: 2.7217 - accuracy: 0.1286 - val_loss: 17.5274 - val_mae: 2.4636 - val_accuracy: 0.1303\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 20.8096 - mae: 2.7012 - accuracy: 0.1280 - val_loss: 17.2342 - val_mae: 2.4630 - val_accuracy: 0.1299\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 20.3427 - mae: 2.6765 - accuracy: 0.1295 - val_loss: 17.2409 - val_mae: 2.4330 - val_accuracy: 0.1318\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 21.0025 - mae: 2.6945 - accuracy: 0.1292 - val_loss: 16.7531 - val_mae: 2.4770 - val_accuracy: 0.1326\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 19.8499 - mae: 2.6477 - accuracy: 0.1295 - val_loss: 16.9008 - val_mae: 2.4187 - val_accuracy: 0.1318\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 20.3706 - mae: 2.6871 - accuracy: 0.1290 - val_loss: 16.3976 - val_mae: 2.4093 - val_accuracy: 0.1318\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.4762 - mae: 2.6033 - accuracy: 0.1286 - val_loss: 16.7380 - val_mae: 2.3848 - val_accuracy: 0.1310\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.9338 - mae: 2.6228 - accuracy: 0.1295 - val_loss: 15.9972 - val_mae: 2.4148 - val_accuracy: 0.1314\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 19.1872 - mae: 2.5938 - accuracy: 0.1298 - val_loss: 16.9327 - val_mae: 2.3860 - val_accuracy: 0.1306\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 19.1313 - mae: 2.5770 - accuracy: 0.1296 - val_loss: 16.5279 - val_mae: 2.4669 - val_accuracy: 0.1318\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.9624 - mae: 2.5677 - accuracy: 0.1286 - val_loss: 16.1290 - val_mae: 2.4314 - val_accuracy: 0.1310\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.2446 - mae: 2.5427 - accuracy: 0.1294 - val_loss: 14.8891 - val_mae: 2.3074 - val_accuracy: 0.1306\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.5262 - mae: 2.5267 - accuracy: 0.1294 - val_loss: 14.9660 - val_mae: 2.3383 - val_accuracy: 0.1310\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.8278 - mae: 2.5719 - accuracy: 0.1291 - val_loss: 15.8851 - val_mae: 2.3272 - val_accuracy: 0.1310\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.0909 - mae: 2.5079 - accuracy: 0.1280 - val_loss: 14.8573 - val_mae: 2.3191 - val_accuracy: 0.1306\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.9803 - mae: 2.4942 - accuracy: 0.1299 - val_loss: 14.7149 - val_mae: 2.2905 - val_accuracy: 0.1306\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.7348 - mae: 2.5040 - accuracy: 0.1301 - val_loss: 14.9429 - val_mae: 2.3225 - val_accuracy: 0.1314\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.7590 - mae: 2.4836 - accuracy: 0.1298 - val_loss: 15.1576 - val_mae: 2.2876 - val_accuracy: 0.1310\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.5821 - mae: 2.4771 - accuracy: 0.1292 - val_loss: 14.9237 - val_mae: 2.2617 - val_accuracy: 0.1314\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 16.8326 - mae: 2.4419 - accuracy: 0.1282 - val_loss: 14.7622 - val_mae: 2.2661 - val_accuracy: 0.1318\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.1991 - mae: 2.4431 - accuracy: 0.1292 - val_loss: 15.3294 - val_mae: 2.2743 - val_accuracy: 0.1306\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.3857 - mae: 2.4624 - accuracy: 0.1295 - val_loss: 14.5431 - val_mae: 2.2940 - val_accuracy: 0.1314\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 16.1932 - mae: 2.3987 - accuracy: 0.1290 - val_loss: 14.8482 - val_mae: 2.2443 - val_accuracy: 0.1310\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.2388 - mae: 2.3901 - accuracy: 0.1273 - val_loss: 14.2750 - val_mae: 2.2557 - val_accuracy: 0.1314\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.9613 - mae: 2.3802 - accuracy: 0.1299 - val_loss: 13.6849 - val_mae: 2.1827 - val_accuracy: 0.1310\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.6960 - mae: 2.3977 - accuracy: 0.1296 - val_loss: 13.9686 - val_mae: 2.2070 - val_accuracy: 0.1310\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 16.4448 - mae: 2.3945 - accuracy: 0.1289 - val_loss: 14.7227 - val_mae: 2.2158 - val_accuracy: 0.1306\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.3067 - mae: 2.3830 - accuracy: 0.1289 - val_loss: 15.1668 - val_mae: 2.2402 - val_accuracy: 0.1306\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.2973 - mae: 2.3864 - accuracy: 0.1291 - val_loss: 13.2437 - val_mae: 2.1624 - val_accuracy: 0.1306\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 15.9577 - mae: 2.3520 - accuracy: 0.1296 - val_loss: 13.5883 - val_mae: 2.1757 - val_accuracy: 0.1310\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.4590 - mae: 2.3769 - accuracy: 0.1290 - val_loss: 13.5525 - val_mae: 2.2106 - val_accuracy: 0.1310\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.9137 - mae: 2.3447 - accuracy: 0.1295 - val_loss: 13.2659 - val_mae: 2.1778 - val_accuracy: 0.1303\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.2277 - mae: 2.3060 - accuracy: 0.1295 - val_loss: 13.0560 - val_mae: 2.1660 - val_accuracy: 0.1306\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 15.5082 - mae: 2.3168 - accuracy: 0.1277 - val_loss: 13.6065 - val_mae: 2.1572 - val_accuracy: 0.1310\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.3336 - mae: 2.3254 - accuracy: 0.1299 - val_loss: 13.3733 - val_mae: 2.1552 - val_accuracy: 0.1310\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 15.1348 - mae: 2.3097 - accuracy: 0.1293 - val_loss: 12.8108 - val_mae: 2.1307 - val_accuracy: 0.1306\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.5831 - mae: 2.3216 - accuracy: 0.1310 - val_loss: 14.5881 - val_mae: 2.1921 - val_accuracy: 0.1306\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 15.4905 - mae: 2.3086 - accuracy: 0.1297 - val_loss: 12.8743 - val_mae: 2.1154 - val_accuracy: 0.1306\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.0046 - mae: 2.2819 - accuracy: 0.1288 - val_loss: 12.7295 - val_mae: 2.1070 - val_accuracy: 0.1306\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.2845 - mae: 2.2454 - accuracy: 0.1290 - val_loss: 13.3916 - val_mae: 2.1163 - val_accuracy: 0.1306\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.5994 - mae: 2.2661 - accuracy: 0.1289 - val_loss: 13.0976 - val_mae: 2.1125 - val_accuracy: 0.1314\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.1868 - mae: 2.2281 - accuracy: 0.1295 - val_loss: 14.1703 - val_mae: 2.1448 - val_accuracy: 0.1314\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 14.7869 - mae: 2.2671 - accuracy: 0.1308 - val_loss: 13.6601 - val_mae: 2.1133 - val_accuracy: 0.1314\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.8282 - mae: 2.2456 - accuracy: 0.1285 - val_loss: 12.6576 - val_mae: 2.0756 - val_accuracy: 0.1314\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 14.4043 - mae: 2.2349 - accuracy: 0.1285 - val_loss: 12.9571 - val_mae: 2.0915 - val_accuracy: 0.1306\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.1442 - mae: 2.2275 - accuracy: 0.1300 - val_loss: 12.5589 - val_mae: 2.0689 - val_accuracy: 0.1314\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.0330 - mae: 2.2229 - accuracy: 0.1302 - val_loss: 12.8169 - val_mae: 2.0789 - val_accuracy: 0.1306\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.0570 - mae: 2.2252 - accuracy: 0.1290 - val_loss: 12.3904 - val_mae: 2.0512 - val_accuracy: 0.1318\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.3017 - mae: 2.2154 - accuracy: 0.1287 - val_loss: 13.6793 - val_mae: 2.1236 - val_accuracy: 0.1310\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 13.9055 - mae: 2.1940 - accuracy: 0.1278 - val_loss: 12.3813 - val_mae: 2.0916 - val_accuracy: 0.1314\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.7360 - mae: 2.1919 - accuracy: 0.1287 - val_loss: 12.2836 - val_mae: 2.0488 - val_accuracy: 0.1318\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.2423 - mae: 2.2319 - accuracy: 0.1285 - val_loss: 11.9083 - val_mae: 2.0219 - val_accuracy: 0.1310\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 13.7605 - mae: 2.1971 - accuracy: 0.1278 - val_loss: 12.8861 - val_mae: 2.0464 - val_accuracy: 0.1306\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.2443 - mae: 2.2066 - accuracy: 0.1302 - val_loss: 11.9342 - val_mae: 2.0174 - val_accuracy: 0.1318\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.5417 - mae: 2.1823 - accuracy: 0.1285 - val_loss: 13.2220 - val_mae: 2.0830 - val_accuracy: 0.1322\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.5854 - mae: 2.1683 - accuracy: 0.1292 - val_loss: 12.2404 - val_mae: 2.0273 - val_accuracy: 0.1318\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.3947 - mae: 2.1527 - accuracy: 0.1292 - val_loss: 11.9246 - val_mae: 1.9930 - val_accuracy: 0.1318\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.8926 - mae: 2.1701 - accuracy: 0.1294 - val_loss: 12.6413 - val_mae: 2.0304 - val_accuracy: 0.1322\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 12.9176 - mae: 2.1369 - accuracy: 0.1301 - val_loss: 12.7055 - val_mae: 2.0264 - val_accuracy: 0.1322\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 13.0499 - mae: 2.1496 - accuracy: 0.1281 - val_loss: 11.7740 - val_mae: 1.9974 - val_accuracy: 0.1310\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 13.6058 - mae: 2.1672 - accuracy: 0.1289 - val_loss: 11.8651 - val_mae: 1.9898 - val_accuracy: 0.1303\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 13.3615 - mae: 2.1609 - accuracy: 0.1294 - val_loss: 11.9901 - val_mae: 2.0037 - val_accuracy: 0.1310\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 12.7500 - mae: 2.1212 - accuracy: 0.1276 - val_loss: 11.7675 - val_mae: 1.9909 - val_accuracy: 0.1314\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 13.1481 - mae: 2.1508 - accuracy: 0.1277 - val_loss: 11.7489 - val_mae: 1.9932 - val_accuracy: 0.1314\n",
      "Kappa Score: 0.9179190946980494\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "WARNING:tensorflow:Layer lstm_138 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_139 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_138 (LSTM)             (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_139 (LSTM)             (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_69 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_69 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 10s 33ms/step - loss: 79.1163 - mae: 5.1893 - accuracy: 0.1206 - val_loss: 61.5709 - val_mae: 4.7370 - val_accuracy: 0.1260\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 57.8468 - mae: 4.5440 - accuracy: 0.1078 - val_loss: 50.4857 - val_mae: 4.2030 - val_accuracy: 0.1037\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 50.5096 - mae: 4.3381 - accuracy: 0.0958 - val_loss: 44.9941 - val_mae: 4.0501 - val_accuracy: 0.0940\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 47.2486 - mae: 4.2771 - accuracy: 0.0886 - val_loss: 42.3538 - val_mae: 3.9464 - val_accuracy: 0.0913\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 46.6520 - mae: 4.2657 - accuracy: 0.0902 - val_loss: 40.9398 - val_mae: 3.9616 - val_accuracy: 0.0987\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 44.9907 - mae: 4.1971 - accuracy: 0.0927 - val_loss: 38.9656 - val_mae: 3.8033 - val_accuracy: 0.0979\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 43.7877 - mae: 4.1144 - accuracy: 0.0960 - val_loss: 38.2991 - val_mae: 3.6822 - val_accuracy: 0.1006\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 43.2881 - mae: 4.0624 - accuracy: 0.1023 - val_loss: 36.7802 - val_mae: 3.6751 - val_accuracy: 0.1129\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 42.3817 - mae: 3.9979 - accuracy: 0.1086 - val_loss: 35.7449 - val_mae: 3.5532 - val_accuracy: 0.1202\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 41.6632 - mae: 3.9311 - accuracy: 0.1182 - val_loss: 34.5545 - val_mae: 3.4891 - val_accuracy: 0.1268\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 40.6642 - mae: 3.8642 - accuracy: 0.1256 - val_loss: 33.9235 - val_mae: 3.4409 - val_accuracy: 0.1383\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 40.0060 - mae: 3.8286 - accuracy: 0.1303 - val_loss: 33.7688 - val_mae: 3.3722 - val_accuracy: 0.1426\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 38.6279 - mae: 3.7551 - accuracy: 0.1307 - val_loss: 34.1315 - val_mae: 3.3262 - val_accuracy: 0.1422\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 38.8692 - mae: 3.7323 - accuracy: 0.1311 - val_loss: 31.9919 - val_mae: 3.3319 - val_accuracy: 0.1422\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 37.7660 - mae: 3.6778 - accuracy: 0.1308 - val_loss: 31.3289 - val_mae: 3.2255 - val_accuracy: 0.1414\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 37.4611 - mae: 3.6500 - accuracy: 0.1311 - val_loss: 30.7886 - val_mae: 3.3609 - val_accuracy: 0.1414\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 34.9525 - mae: 3.5300 - accuracy: 0.1301 - val_loss: 29.5603 - val_mae: 3.2718 - val_accuracy: 0.1410\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 35.4889 - mae: 3.5339 - accuracy: 0.1296 - val_loss: 29.0722 - val_mae: 3.2607 - val_accuracy: 0.1410\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 33.8617 - mae: 3.4770 - accuracy: 0.1285 - val_loss: 27.7703 - val_mae: 3.1166 - val_accuracy: 0.1403\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 32.8480 - mae: 3.3961 - accuracy: 0.1286 - val_loss: 27.1106 - val_mae: 3.0757 - val_accuracy: 0.1395\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 31.7338 - mae: 3.3454 - accuracy: 0.1289 - val_loss: 26.0807 - val_mae: 2.9837 - val_accuracy: 0.1395\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 31.6501 - mae: 3.3334 - accuracy: 0.1273 - val_loss: 26.9501 - val_mae: 2.9509 - val_accuracy: 0.1391\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 30.2313 - mae: 3.2702 - accuracy: 0.1283 - val_loss: 25.0511 - val_mae: 2.9211 - val_accuracy: 0.1387\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 29.8068 - mae: 3.2341 - accuracy: 0.1276 - val_loss: 24.5203 - val_mae: 2.8745 - val_accuracy: 0.1395\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 28.4974 - mae: 3.1554 - accuracy: 0.1274 - val_loss: 26.3548 - val_mae: 2.8815 - val_accuracy: 0.1387\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 27.4984 - mae: 3.1034 - accuracy: 0.1267 - val_loss: 23.4895 - val_mae: 2.8620 - val_accuracy: 0.1391\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 27.1168 - mae: 3.0798 - accuracy: 0.1279 - val_loss: 24.0228 - val_mae: 2.7895 - val_accuracy: 0.1387\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 27.1826 - mae: 3.0781 - accuracy: 0.1281 - val_loss: 22.8057 - val_mae: 2.8458 - val_accuracy: 0.1395\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 26.5340 - mae: 3.0430 - accuracy: 0.1282 - val_loss: 22.4288 - val_mae: 2.7639 - val_accuracy: 0.1395\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.9700 - mae: 3.0018 - accuracy: 0.1282 - val_loss: 22.2723 - val_mae: 2.7323 - val_accuracy: 0.1395\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.8101 - mae: 2.9829 - accuracy: 0.1277 - val_loss: 22.0681 - val_mae: 2.6972 - val_accuracy: 0.1399\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.0337 - mae: 2.9388 - accuracy: 0.1288 - val_loss: 21.7056 - val_mae: 2.6890 - val_accuracy: 0.1395\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.0288 - mae: 2.9346 - accuracy: 0.1289 - val_loss: 20.9868 - val_mae: 2.6753 - val_accuracy: 0.1395\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 25.0496 - mae: 2.9153 - accuracy: 0.1289 - val_loss: 20.8654 - val_mae: 2.6354 - val_accuracy: 0.1403\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 24.5006 - mae: 2.9039 - accuracy: 0.1299 - val_loss: 21.8721 - val_mae: 2.6527 - val_accuracy: 0.1410\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.6954 - mae: 2.9016 - accuracy: 0.1293 - val_loss: 20.6823 - val_mae: 2.6021 - val_accuracy: 0.1434\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.5170 - mae: 2.9039 - accuracy: 0.1294 - val_loss: 19.9970 - val_mae: 2.6498 - val_accuracy: 0.1426\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.0446 - mae: 2.8656 - accuracy: 0.1289 - val_loss: 20.6308 - val_mae: 2.6996 - val_accuracy: 0.1426\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 23.0136 - mae: 2.8153 - accuracy: 0.1299 - val_loss: 20.3638 - val_mae: 2.6827 - val_accuracy: 0.1418\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 23.1104 - mae: 2.8161 - accuracy: 0.1297 - val_loss: 20.2217 - val_mae: 2.5666 - val_accuracy: 0.1426\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 22.1131 - mae: 2.7578 - accuracy: 0.1294 - val_loss: 19.2928 - val_mae: 2.5783 - val_accuracy: 0.1422\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 22.6029 - mae: 2.7804 - accuracy: 0.1290 - val_loss: 19.3581 - val_mae: 2.5496 - val_accuracy: 0.1422\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.2512 - mae: 2.7433 - accuracy: 0.1295 - val_loss: 20.5989 - val_mae: 2.5505 - val_accuracy: 0.1418\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 22.4954 - mae: 2.7569 - accuracy: 0.1291 - val_loss: 20.0313 - val_mae: 2.5322 - val_accuracy: 0.1426\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 21.7030 - mae: 2.7219 - accuracy: 0.1292 - val_loss: 19.0016 - val_mae: 2.5105 - val_accuracy: 0.1414\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 21.4959 - mae: 2.6919 - accuracy: 0.1284 - val_loss: 18.7377 - val_mae: 2.4966 - val_accuracy: 0.1418\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 21.7528 - mae: 2.7110 - accuracy: 0.1296 - val_loss: 19.9053 - val_mae: 2.5059 - val_accuracy: 0.1414\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 21.5828 - mae: 2.6910 - accuracy: 0.1292 - val_loss: 18.1941 - val_mae: 2.4890 - val_accuracy: 0.1418\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.1814 - mae: 2.6739 - accuracy: 0.1287 - val_loss: 19.7721 - val_mae: 2.5265 - val_accuracy: 0.1410\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.8677 - mae: 2.6697 - accuracy: 0.1299 - val_loss: 18.9066 - val_mae: 2.4622 - val_accuracy: 0.1418\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.1339 - mae: 2.6625 - accuracy: 0.1291 - val_loss: 17.9032 - val_mae: 2.4939 - val_accuracy: 0.1410\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.8758 - mae: 2.6027 - accuracy: 0.1298 - val_loss: 18.0103 - val_mae: 2.4610 - val_accuracy: 0.1410\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.8070 - mae: 2.5998 - accuracy: 0.1292 - val_loss: 17.6433 - val_mae: 2.4601 - val_accuracy: 0.1414\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.9488 - mae: 2.6009 - accuracy: 0.1289 - val_loss: 17.5767 - val_mae: 2.4149 - val_accuracy: 0.1422\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.4479 - mae: 2.5749 - accuracy: 0.1300 - val_loss: 17.8727 - val_mae: 2.4225 - val_accuracy: 0.1414\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.7931 - mae: 2.5818 - accuracy: 0.1283 - val_loss: 17.3963 - val_mae: 2.4101 - val_accuracy: 0.1407\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.4293 - mae: 2.5770 - accuracy: 0.1298 - val_loss: 17.1604 - val_mae: 2.4264 - val_accuracy: 0.1410\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.5491 - mae: 2.5844 - accuracy: 0.1291 - val_loss: 17.5783 - val_mae: 2.4181 - val_accuracy: 0.1403\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.3794 - mae: 2.5628 - accuracy: 0.1286 - val_loss: 17.1390 - val_mae: 2.3991 - val_accuracy: 0.1418\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.2136 - mae: 2.5460 - accuracy: 0.1289 - val_loss: 16.8068 - val_mae: 2.3715 - val_accuracy: 0.1410\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.8833 - mae: 2.5345 - accuracy: 0.1285 - val_loss: 17.1536 - val_mae: 2.3629 - val_accuracy: 0.1410\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 18.3460 - mae: 2.5200 - accuracy: 0.1278 - val_loss: 16.8788 - val_mae: 2.3573 - val_accuracy: 0.1410\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.0178 - mae: 2.4888 - accuracy: 0.1285 - val_loss: 16.8311 - val_mae: 2.3904 - val_accuracy: 0.1410\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.5182 - mae: 2.5126 - accuracy: 0.1286 - val_loss: 16.4585 - val_mae: 2.3181 - val_accuracy: 0.1403\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.6469 - mae: 2.4562 - accuracy: 0.1280 - val_loss: 16.7530 - val_mae: 2.3333 - val_accuracy: 0.1399\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.9540 - mae: 2.4906 - accuracy: 0.1290 - val_loss: 17.9366 - val_mae: 2.4986 - val_accuracy: 0.1399\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.7139 - mae: 2.4691 - accuracy: 0.1277 - val_loss: 16.3334 - val_mae: 2.3032 - val_accuracy: 0.1407\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.5648 - mae: 2.4573 - accuracy: 0.1289 - val_loss: 16.2583 - val_mae: 2.3100 - val_accuracy: 0.1403\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.2061 - mae: 2.4340 - accuracy: 0.1289 - val_loss: 16.2166 - val_mae: 2.3199 - val_accuracy: 0.1410\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.7775 - mae: 2.4575 - accuracy: 0.1278 - val_loss: 15.8167 - val_mae: 2.3065 - val_accuracy: 0.1407\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.0012 - mae: 2.4258 - accuracy: 0.1286 - val_loss: 16.1851 - val_mae: 2.2908 - val_accuracy: 0.1407\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.2370 - mae: 2.4148 - accuracy: 0.1290 - val_loss: 15.9597 - val_mae: 2.2869 - val_accuracy: 0.1410\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.1974 - mae: 2.4287 - accuracy: 0.1267 - val_loss: 15.9693 - val_mae: 2.2842 - val_accuracy: 0.1407\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 16.7769 - mae: 2.3990 - accuracy: 0.1263 - val_loss: 15.8572 - val_mae: 2.2810 - val_accuracy: 0.1399\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.0731 - mae: 2.4175 - accuracy: 0.1277 - val_loss: 16.5619 - val_mae: 2.2942 - val_accuracy: 0.1395\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.9517 - mae: 2.4059 - accuracy: 0.1286 - val_loss: 16.8205 - val_mae: 2.3048 - val_accuracy: 0.1391\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.4762 - mae: 2.3806 - accuracy: 0.1273 - val_loss: 15.4347 - val_mae: 2.2544 - val_accuracy: 0.1395\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 16.8253 - mae: 2.4047 - accuracy: 0.1266 - val_loss: 15.7556 - val_mae: 2.3236 - val_accuracy: 0.1399\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 16.2769 - mae: 2.3746 - accuracy: 0.1265 - val_loss: 15.5088 - val_mae: 2.2688 - val_accuracy: 0.1387\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.8927 - mae: 2.3421 - accuracy: 0.1277 - val_loss: 15.0703 - val_mae: 2.2424 - val_accuracy: 0.1391\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.9040 - mae: 2.3396 - accuracy: 0.1275 - val_loss: 15.3660 - val_mae: 2.2512 - val_accuracy: 0.1395\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.5024 - mae: 2.3447 - accuracy: 0.1277 - val_loss: 16.1247 - val_mae: 2.3621 - val_accuracy: 0.1399\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 16.2222 - mae: 2.3635 - accuracy: 0.1280 - val_loss: 15.6159 - val_mae: 2.2406 - val_accuracy: 0.1399\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.9245 - mae: 2.3300 - accuracy: 0.1264 - val_loss: 17.0112 - val_mae: 2.4103 - val_accuracy: 0.1403\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.9808 - mae: 2.3331 - accuracy: 0.1273 - val_loss: 14.9565 - val_mae: 2.2235 - val_accuracy: 0.1403\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.7174 - mae: 2.3306 - accuracy: 0.1262 - val_loss: 14.9471 - val_mae: 2.2436 - val_accuracy: 0.1399\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.4528 - mae: 2.3010 - accuracy: 0.1273 - val_loss: 15.0317 - val_mae: 2.2665 - val_accuracy: 0.1395\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.7698 - mae: 2.3094 - accuracy: 0.1254 - val_loss: 14.9094 - val_mae: 2.2196 - val_accuracy: 0.1403\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 15.1758 - mae: 2.2915 - accuracy: 0.1260 - val_loss: 14.7455 - val_mae: 2.2350 - val_accuracy: 0.1395\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.5267 - mae: 2.3067 - accuracy: 0.1259 - val_loss: 14.8292 - val_mae: 2.2193 - val_accuracy: 0.1395\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.8822 - mae: 2.2709 - accuracy: 0.1254 - val_loss: 14.7660 - val_mae: 2.2368 - val_accuracy: 0.1395\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.3198 - mae: 2.2873 - accuracy: 0.1269 - val_loss: 15.9371 - val_mae: 2.3266 - val_accuracy: 0.1391\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.2492 - mae: 2.2880 - accuracy: 0.1277 - val_loss: 16.3542 - val_mae: 2.2432 - val_accuracy: 0.1395\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.2888 - mae: 2.2958 - accuracy: 0.1270 - val_loss: 14.5498 - val_mae: 2.2036 - val_accuracy: 0.1399\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 14.3323 - mae: 2.2290 - accuracy: 0.1259 - val_loss: 15.3515 - val_mae: 2.2140 - val_accuracy: 0.1387\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 14.3763 - mae: 2.2265 - accuracy: 0.1274 - val_loss: 14.7277 - val_mae: 2.1788 - val_accuracy: 0.1391\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.6718 - mae: 2.2459 - accuracy: 0.1265 - val_loss: 14.2619 - val_mae: 2.1909 - val_accuracy: 0.1403\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 14.3659 - mae: 2.2251 - accuracy: 0.1265 - val_loss: 14.4242 - val_mae: 2.1921 - val_accuracy: 0.1395\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.4765 - mae: 2.2263 - accuracy: 0.1265 - val_loss: 14.9623 - val_mae: 2.2867 - val_accuracy: 0.1387\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 14.5667 - mae: 2.2432 - accuracy: 0.1256 - val_loss: 14.7398 - val_mae: 2.2605 - val_accuracy: 0.1383\n",
      "Kappa Score: 0.9069747314980696\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "Training Word2Vec Model...\n",
      "WARNING:tensorflow:Layer lstm_140 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_141 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_70\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_140 (LSTM)             (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_141 (LSTM)             (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_70 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 9s 21ms/step - loss: 81.5041 - mae: 5.2139 - accuracy: 0.1214 - val_loss: 68.9407 - val_mae: 4.9395 - val_accuracy: 0.1245\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 65.8344 - mae: 4.9077 - accuracy: 0.1205 - val_loss: 62.5047 - val_mae: 4.7735 - val_accuracy: 0.1125\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 60.7974 - mae: 4.7757 - accuracy: 0.1115 - val_loss: 58.0241 - val_mae: 4.6089 - val_accuracy: 0.1052\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 58.2130 - mae: 4.7062 - accuracy: 0.1069 - val_loss: 54.4716 - val_mae: 4.5248 - val_accuracy: 0.1064\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 56.2112 - mae: 4.6605 - accuracy: 0.1027 - val_loss: 51.2952 - val_mae: 4.4112 - val_accuracy: 0.1091\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 54.9213 - mae: 4.6241 - accuracy: 0.1038 - val_loss: 49.6584 - val_mae: 4.3817 - val_accuracy: 0.1094\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 54.0528 - mae: 4.6141 - accuracy: 0.1047 - val_loss: 47.5987 - val_mae: 4.2014 - val_accuracy: 0.1094\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 52.2756 - mae: 4.5259 - accuracy: 0.1064 - val_loss: 46.5374 - val_mae: 4.3441 - val_accuracy: 0.1102\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 49.7357 - mae: 4.4316 - accuracy: 0.1073 - val_loss: 42.6901 - val_mae: 4.0725 - val_accuracy: 0.1106\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 49.1325 - mae: 4.3826 - accuracy: 0.1075 - val_loss: 41.3542 - val_mae: 3.9001 - val_accuracy: 0.1110\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 46.9873 - mae: 4.2857 - accuracy: 0.1095 - val_loss: 39.0962 - val_mae: 3.8422 - val_accuracy: 0.1121\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 46.2064 - mae: 4.2259 - accuracy: 0.1143 - val_loss: 37.7342 - val_mae: 3.7000 - val_accuracy: 0.1148\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 44.6901 - mae: 4.1342 - accuracy: 0.1156 - val_loss: 37.2094 - val_mae: 3.5688 - val_accuracy: 0.1148\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 43.5620 - mae: 4.0755 - accuracy: 0.1199 - val_loss: 34.3781 - val_mae: 3.5255 - val_accuracy: 0.1152\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 41.4927 - mae: 3.9761 - accuracy: 0.1203 - val_loss: 33.5915 - val_mae: 3.4296 - val_accuracy: 0.1152\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 40.4125 - mae: 3.8997 - accuracy: 0.1205 - val_loss: 32.8213 - val_mae: 3.6578 - val_accuracy: 0.1160\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 39.3398 - mae: 3.8698 - accuracy: 0.1228 - val_loss: 30.1739 - val_mae: 3.2846 - val_accuracy: 0.1156\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 36.9516 - mae: 3.7145 - accuracy: 0.1227 - val_loss: 29.4416 - val_mae: 3.5156 - val_accuracy: 0.1179\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 36.6465 - mae: 3.6883 - accuracy: 0.1220 - val_loss: 26.9077 - val_mae: 3.1990 - val_accuracy: 0.1183\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 35.4860 - mae: 3.6239 - accuracy: 0.1222 - val_loss: 26.7403 - val_mae: 3.0850 - val_accuracy: 0.1191\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 35.0402 - mae: 3.5964 - accuracy: 0.1242 - val_loss: 25.1886 - val_mae: 3.0283 - val_accuracy: 0.1210\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 33.4245 - mae: 3.5093 - accuracy: 0.1269 - val_loss: 24.8898 - val_mae: 3.0374 - val_accuracy: 0.1198\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 32.4875 - mae: 3.4458 - accuracy: 0.1248 - val_loss: 24.2813 - val_mae: 2.9405 - val_accuracy: 0.1206\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 31.7614 - mae: 3.4097 - accuracy: 0.1268 - val_loss: 24.5542 - val_mae: 2.9283 - val_accuracy: 0.1218\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 30.7844 - mae: 3.3568 - accuracy: 0.1286 - val_loss: 22.4056 - val_mae: 2.9152 - val_accuracy: 0.1210\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 30.4357 - mae: 3.3175 - accuracy: 0.1268 - val_loss: 22.5324 - val_mae: 2.8656 - val_accuracy: 0.1206\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 29.9538 - mae: 3.2895 - accuracy: 0.1278 - val_loss: 22.5227 - val_mae: 2.8952 - val_accuracy: 0.1206\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 28.8978 - mae: 3.2463 - accuracy: 0.1274 - val_loss: 22.1905 - val_mae: 2.8234 - val_accuracy: 0.1202\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 28.8364 - mae: 3.2491 - accuracy: 0.1269 - val_loss: 20.8454 - val_mae: 2.8053 - val_accuracy: 0.1206\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 28.0416 - mae: 3.2131 - accuracy: 0.1273 - val_loss: 21.0429 - val_mae: 2.7863 - val_accuracy: 0.1229\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 28.3807 - mae: 3.1957 - accuracy: 0.1287 - val_loss: 20.4810 - val_mae: 2.8104 - val_accuracy: 0.1233\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 26.7089 - mae: 3.1302 - accuracy: 0.1282 - val_loss: 20.5685 - val_mae: 2.7739 - val_accuracy: 0.1237\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 26.3649 - mae: 3.1180 - accuracy: 0.1282 - val_loss: 20.0751 - val_mae: 2.7935 - val_accuracy: 0.1249\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 26.9690 - mae: 3.1434 - accuracy: 0.1283 - val_loss: 20.1174 - val_mae: 2.7628 - val_accuracy: 0.1252\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 26.4797 - mae: 3.1059 - accuracy: 0.1300 - val_loss: 19.7916 - val_mae: 2.7762 - val_accuracy: 0.1249\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.4883 - mae: 3.0479 - accuracy: 0.1287 - val_loss: 20.4702 - val_mae: 2.8432 - val_accuracy: 0.1252\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.9073 - mae: 3.0511 - accuracy: 0.1283 - val_loss: 20.1669 - val_mae: 2.7393 - val_accuracy: 0.1260\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 2s 14ms/step - loss: 24.5302 - mae: 2.9958 - accuracy: 0.1287 - val_loss: 20.2281 - val_mae: 2.6748 - val_accuracy: 0.1260\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.8308 - mae: 3.0001 - accuracy: 0.1291 - val_loss: 19.1783 - val_mae: 2.7106 - val_accuracy: 0.1260\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.2956 - mae: 2.9751 - accuracy: 0.1281 - val_loss: 19.2721 - val_mae: 2.6683 - val_accuracy: 0.1260\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 23.6231 - mae: 2.9199 - accuracy: 0.1289 - val_loss: 19.1738 - val_mae: 2.7250 - val_accuracy: 0.1264\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 24.3109 - mae: 2.9520 - accuracy: 0.1279 - val_loss: 20.0150 - val_mae: 2.7752 - val_accuracy: 0.1264\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 23.4637 - mae: 2.9072 - accuracy: 0.1278 - val_loss: 18.8401 - val_mae: 2.6155 - val_accuracy: 0.1268\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.9582 - mae: 2.8628 - accuracy: 0.1294 - val_loss: 20.2791 - val_mae: 2.6320 - val_accuracy: 0.1256\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 23.3360 - mae: 2.8888 - accuracy: 0.1293 - val_loss: 18.7042 - val_mae: 2.6612 - val_accuracy: 0.1272\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.9263 - mae: 2.8559 - accuracy: 0.1291 - val_loss: 18.7371 - val_mae: 2.5968 - val_accuracy: 0.1268\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.4724 - mae: 2.8383 - accuracy: 0.1299 - val_loss: 18.1301 - val_mae: 2.6341 - val_accuracy: 0.1268\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 23.2165 - mae: 2.8777 - accuracy: 0.1301 - val_loss: 18.5326 - val_mae: 2.6466 - val_accuracy: 0.1260\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.9516 - mae: 2.8844 - accuracy: 0.1292 - val_loss: 18.0345 - val_mae: 2.5907 - val_accuracy: 0.1272\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.4002 - mae: 2.8175 - accuracy: 0.1278 - val_loss: 17.5735 - val_mae: 2.6139 - val_accuracy: 0.1268\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 22.4323 - mae: 2.8231 - accuracy: 0.1293 - val_loss: 18.2785 - val_mae: 2.6504 - val_accuracy: 0.1272\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.3505 - mae: 2.8136 - accuracy: 0.1277 - val_loss: 18.3656 - val_mae: 2.5970 - val_accuracy: 0.1264\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 22.6852 - mae: 2.8059 - accuracy: 0.1286 - val_loss: 17.8089 - val_mae: 2.5519 - val_accuracy: 0.1264\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 21.9309 - mae: 2.7765 - accuracy: 0.1295 - val_loss: 17.9355 - val_mae: 2.5237 - val_accuracy: 0.1264\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 22.1874 - mae: 2.8003 - accuracy: 0.1274 - val_loss: 18.0361 - val_mae: 2.5255 - val_accuracy: 0.1256\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.6163 - mae: 2.7801 - accuracy: 0.1299 - val_loss: 17.3978 - val_mae: 2.5085 - val_accuracy: 0.1260\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.5554 - mae: 2.7589 - accuracy: 0.1279 - val_loss: 17.7166 - val_mae: 2.5202 - val_accuracy: 0.1264\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 21.0263 - mae: 2.7438 - accuracy: 0.1278 - val_loss: 17.2713 - val_mae: 2.5116 - val_accuracy: 0.1260\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 21.1673 - mae: 2.7399 - accuracy: 0.1273 - val_loss: 17.6048 - val_mae: 2.5113 - val_accuracy: 0.1256\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.2778 - mae: 2.7254 - accuracy: 0.1275 - val_loss: 17.7336 - val_mae: 2.5074 - val_accuracy: 0.1268\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.7686 - mae: 2.7301 - accuracy: 0.1284 - val_loss: 18.1115 - val_mae: 2.5108 - val_accuracy: 0.1233\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.0917 - mae: 2.6799 - accuracy: 0.1276 - val_loss: 16.5380 - val_mae: 2.4842 - val_accuracy: 0.1268\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.6267 - mae: 2.7056 - accuracy: 0.1278 - val_loss: 17.1301 - val_mae: 2.4913 - val_accuracy: 0.1264\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.4208 - mae: 2.6970 - accuracy: 0.1261 - val_loss: 17.3296 - val_mae: 2.4924 - val_accuracy: 0.1264\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.8574 - mae: 2.6734 - accuracy: 0.1282 - val_loss: 17.0383 - val_mae: 2.5281 - val_accuracy: 0.1264\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 20.5930 - mae: 2.7009 - accuracy: 0.1289 - val_loss: 16.9164 - val_mae: 2.4862 - val_accuracy: 0.1268\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 19.3278 - mae: 2.6456 - accuracy: 0.1290 - val_loss: 17.0561 - val_mae: 2.4735 - val_accuracy: 0.1260\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 19.9443 - mae: 2.6620 - accuracy: 0.1288 - val_loss: 17.0251 - val_mae: 2.4657 - val_accuracy: 0.1268\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 20.5154 - mae: 2.6832 - accuracy: 0.1285 - val_loss: 16.5552 - val_mae: 2.4670 - val_accuracy: 0.1268\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.2490 - mae: 2.6227 - accuracy: 0.1283 - val_loss: 16.3635 - val_mae: 2.4265 - val_accuracy: 0.1245\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 19.7782 - mae: 2.6551 - accuracy: 0.1283 - val_loss: 16.6484 - val_mae: 2.4410 - val_accuracy: 0.1276\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.8051 - mae: 2.6561 - accuracy: 0.1283 - val_loss: 16.6564 - val_mae: 2.4336 - val_accuracy: 0.1249\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 19.7196 - mae: 2.6479 - accuracy: 0.1288 - val_loss: 16.8895 - val_mae: 2.4211 - val_accuracy: 0.1272\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.5998 - mae: 2.6309 - accuracy: 0.1289 - val_loss: 15.9974 - val_mae: 2.4282 - val_accuracy: 0.1268\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.2875 - mae: 2.6262 - accuracy: 0.1288 - val_loss: 15.8707 - val_mae: 2.4243 - val_accuracy: 0.1268\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 18.5863 - mae: 2.5914 - accuracy: 0.1280 - val_loss: 16.1086 - val_mae: 2.4597 - val_accuracy: 0.1268\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.9335 - mae: 2.6056 - accuracy: 0.1299 - val_loss: 16.4510 - val_mae: 2.4436 - val_accuracy: 0.1268\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.3708 - mae: 2.6263 - accuracy: 0.1279 - val_loss: 16.5029 - val_mae: 2.5026 - val_accuracy: 0.1268\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 18.7452 - mae: 2.5941 - accuracy: 0.1275 - val_loss: 16.6054 - val_mae: 2.4174 - val_accuracy: 0.1264\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 17.9184 - mae: 2.5514 - accuracy: 0.1285 - val_loss: 16.3819 - val_mae: 2.4333 - val_accuracy: 0.1264\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 18.8766 - mae: 2.5817 - accuracy: 0.1295 - val_loss: 16.2602 - val_mae: 2.4089 - val_accuracy: 0.1264\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 18.8045 - mae: 2.5812 - accuracy: 0.1281 - val_loss: 15.9363 - val_mae: 2.3765 - val_accuracy: 0.1241\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 17.9612 - mae: 2.5575 - accuracy: 0.1280 - val_loss: 15.8348 - val_mae: 2.3917 - val_accuracy: 0.1264\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 18.6688 - mae: 2.5629 - accuracy: 0.1287 - val_loss: 15.9230 - val_mae: 2.4094 - val_accuracy: 0.1237\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 18.4382 - mae: 2.5594 - accuracy: 0.1282 - val_loss: 16.0273 - val_mae: 2.4025 - val_accuracy: 0.1260\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 18.5532 - mae: 2.5704 - accuracy: 0.1277 - val_loss: 16.2742 - val_mae: 2.4284 - val_accuracy: 0.1252\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.3759 - mae: 2.5429 - accuracy: 0.1294 - val_loss: 15.5033 - val_mae: 2.3517 - val_accuracy: 0.1229\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.5083 - mae: 2.5641 - accuracy: 0.1288 - val_loss: 15.5636 - val_mae: 2.3664 - val_accuracy: 0.1233\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 18.3060 - mae: 2.5598 - accuracy: 0.1286 - val_loss: 15.8998 - val_mae: 2.3956 - val_accuracy: 0.1256\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.5476 - mae: 2.5194 - accuracy: 0.1284 - val_loss: 15.8147 - val_mae: 2.3534 - val_accuracy: 0.1260\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 18.0309 - mae: 2.5280 - accuracy: 0.1289 - val_loss: 15.5217 - val_mae: 2.3634 - val_accuracy: 0.1237\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.8460 - mae: 2.5210 - accuracy: 0.1295 - val_loss: 16.0659 - val_mae: 2.4319 - val_accuracy: 0.1260\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 18.3523 - mae: 2.5281 - accuracy: 0.1303 - val_loss: 15.5388 - val_mae: 2.3936 - val_accuracy: 0.1260\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.2189 - mae: 2.4839 - accuracy: 0.1294 - val_loss: 16.5178 - val_mae: 2.4246 - val_accuracy: 0.1264\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 17.1732 - mae: 2.4865 - accuracy: 0.1309 - val_loss: 15.6559 - val_mae: 2.3660 - val_accuracy: 0.1245\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.3645 - mae: 2.4989 - accuracy: 0.1277 - val_loss: 15.6708 - val_mae: 2.3681 - val_accuracy: 0.1272\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 17.7394 - mae: 2.5031 - accuracy: 0.1286 - val_loss: 15.9145 - val_mae: 2.4362 - val_accuracy: 0.1264\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.3069 - mae: 2.4801 - accuracy: 0.1289 - val_loss: 15.4860 - val_mae: 2.3563 - val_accuracy: 0.1260\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.1892 - mae: 2.4918 - accuracy: 0.1279 - val_loss: 16.5446 - val_mae: 2.3717 - val_accuracy: 0.1245\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 17.0410 - mae: 2.4475 - accuracy: 0.1296 - val_loss: 15.5409 - val_mae: 2.3361 - val_accuracy: 0.1272\n",
      "Kappa Score: 0.8941286025768856\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits = 5, shuffle = True)\n",
    "results = []\n",
    "y_pred_list = []\n",
    "\n",
    "count = 1\n",
    "for traincv, testcv in cv.split(X):\n",
    "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "    X_test, X_train, y_test, y_train = X.iloc[testcv], X.iloc[traincv], y.iloc[testcv], y.iloc[traincv]\n",
    "    \n",
    "    train_essays = X_train['essay']\n",
    "    test_essays = X_test['essay']\n",
    "    \n",
    "    sentences = []\n",
    "    sentences_test = []\n",
    "    clean_train_essays = []\n",
    "    clean_test_essays = []\n",
    "    for essay in train_essays:\n",
    "        sentences += sentences_from_essay(essay, remove_stopwords = True)\n",
    "    for test_essay in test_essays:\n",
    "        sentences_test += sentences_from_essay(test_essay, remove_stopwords = True)\n",
    "    for essay_v in train_essays:\n",
    "        clean_train_essays.append(wordlist_from_essay(essay_v, remove_stopwords=True))\n",
    "    for test_essay in test_essays:\n",
    "        clean_test_essays.append(wordlist_from_essay(test_essay, remove_stopwords=True))\n",
    "            \n",
    "    num_features = 300\n",
    "    min_word_count = 40\n",
    "    num_workers = 8\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    model = Word2Vec(sentences, workers=num_workers, vector_size=num_features, min_count = min_word_count, window = context, sample = downsampling)\n",
    "\n",
    "    model.init_sims(replace=True)\n",
    "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "\n",
    "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
    "    testDataVecs = getAvgFeatureVecs(clean_test_essays, model, num_features)\n",
    "    clean_test_essays = []\n",
    "    for essay_v in test_essays:\n",
    "        clean_test_essays.append(wordlist_from_essay( essay_v, remove_stopwords=True ))\n",
    "    testDataVecs = getAvgFeatureVecs( clean_test_essays, model, num_features )\n",
    "    \n",
    "    trainDataVecs = np.array(trainDataVecs)\n",
    "    testDataVecs = np.array(testDataVecs)\n",
    "    # Reshaping train and test vectors to 3 dimensions. (1 represnts one timestep)\n",
    "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "    \n",
    "    lstm_model = get_model()\n",
    "    history = lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=100, validation_data=(testDataVecs, y_test))\n",
    "    #lstm_model.load_weights('./model_weights/final_lstm.h5')\n",
    "    y_pred = lstm_model.predict(testDataVecs)\n",
    "     \n",
    "    # Save any one of the 5 models.\n",
    "    if count == 5:\n",
    "         lstm_model.save_weights('final_lstm.h5')\n",
    "    \n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred = np.around(y_pred)\n",
    "    \n",
    "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "    result = cohen_kappa_score(y_test.values,y_pred,weights='quadratic')\n",
    "    print(\"Kappa Score: {}\".format(result))\n",
    "    results.append(result)\n",
    "\n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------Fold 1--------\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_142 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_143 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_71\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_142 (LSTM)             (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_143 (LSTM)             (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_71 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 7s 19ms/step - loss: 79.0831 - mae: 5.3330 - accuracy: 0.1175 - val_loss: 65.6250 - val_mae: 5.0033 - val_accuracy: 0.1171\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 63.7208 - mae: 4.9943 - accuracy: 0.1174 - val_loss: 58.9483 - val_mae: 4.6372 - val_accuracy: 0.1032\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 58.2039 - mae: 4.7897 - accuracy: 0.1105 - val_loss: 53.5194 - val_mae: 4.6492 - val_accuracy: 0.1063\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 54.2721 - mae: 4.6948 - accuracy: 0.1102 - val_loss: 49.0749 - val_mae: 4.3422 - val_accuracy: 0.1113\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 52.3825 - mae: 4.6076 - accuracy: 0.1126 - val_loss: 47.5689 - val_mae: 4.2968 - val_accuracy: 0.1129\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 49.3891 - mae: 4.4887 - accuracy: 0.1145 - val_loss: 44.1630 - val_mae: 4.0287 - val_accuracy: 0.1125\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 47.7918 - mae: 4.3817 - accuracy: 0.1173 - val_loss: 41.9166 - val_mae: 3.9109 - val_accuracy: 0.1179\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 45.8889 - mae: 4.2978 - accuracy: 0.1195 - val_loss: 39.8240 - val_mae: 3.8097 - val_accuracy: 0.1194\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 43.1694 - mae: 4.1451 - accuracy: 0.1208 - val_loss: 38.4702 - val_mae: 3.6945 - val_accuracy: 0.1233\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 41.4268 - mae: 4.0269 - accuracy: 0.1264 - val_loss: 35.3359 - val_mae: 3.5781 - val_accuracy: 0.1206\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 39.0810 - mae: 3.8952 - accuracy: 0.1278 - val_loss: 35.7141 - val_mae: 3.4978 - val_accuracy: 0.1229\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 37.6047 - mae: 3.7861 - accuracy: 0.1285 - val_loss: 31.1465 - val_mae: 3.4636 - val_accuracy: 0.1263\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 35.7876 - mae: 3.6866 - accuracy: 0.1299 - val_loss: 30.1503 - val_mae: 3.3363 - val_accuracy: 0.1237\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 33.9644 - mae: 3.5924 - accuracy: 0.1280 - val_loss: 28.8511 - val_mae: 3.2530 - val_accuracy: 0.1229\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 32.6137 - mae: 3.4896 - accuracy: 0.1290 - val_loss: 28.1014 - val_mae: 3.1961 - val_accuracy: 0.1221\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 32.1230 - mae: 3.4631 - accuracy: 0.1276 - val_loss: 27.7065 - val_mae: 3.1561 - val_accuracy: 0.1217\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 31.3012 - mae: 3.4461 - accuracy: 0.1257 - val_loss: 26.6361 - val_mae: 3.2704 - val_accuracy: 0.1213\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 31.4178 - mae: 3.4395 - accuracy: 0.1255 - val_loss: 25.8417 - val_mae: 3.1472 - val_accuracy: 0.1206\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 29.7239 - mae: 3.3599 - accuracy: 0.1250 - val_loss: 26.5462 - val_mae: 3.0741 - val_accuracy: 0.1186\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 29.1435 - mae: 3.3156 - accuracy: 0.1249 - val_loss: 24.9765 - val_mae: 3.0725 - val_accuracy: 0.1175\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 28.4982 - mae: 3.2809 - accuracy: 0.1251 - val_loss: 24.2309 - val_mae: 3.0431 - val_accuracy: 0.1198\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 28.0820 - mae: 3.2700 - accuracy: 0.1248 - val_loss: 24.8720 - val_mae: 3.1054 - val_accuracy: 0.1183\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 27.3738 - mae: 3.2381 - accuracy: 0.1245 - val_loss: 23.9344 - val_mae: 3.0142 - val_accuracy: 0.1183\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 27.7530 - mae: 3.2161 - accuracy: 0.1221 - val_loss: 23.8948 - val_mae: 2.9793 - val_accuracy: 0.1179\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 26.8023 - mae: 3.2067 - accuracy: 0.1247 - val_loss: 23.0930 - val_mae: 3.0151 - val_accuracy: 0.1190\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.5336 - mae: 3.1151 - accuracy: 0.1246 - val_loss: 22.0122 - val_mae: 2.9483 - val_accuracy: 0.1175\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 25.4951 - mae: 3.1197 - accuracy: 0.1243 - val_loss: 21.9359 - val_mae: 2.8814 - val_accuracy: 0.1190\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.3074 - mae: 3.1058 - accuracy: 0.1220 - val_loss: 21.5426 - val_mae: 2.8701 - val_accuracy: 0.1190\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.9756 - mae: 3.0870 - accuracy: 0.1242 - val_loss: 21.8667 - val_mae: 2.8552 - val_accuracy: 0.1171\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 24.1266 - mae: 3.0227 - accuracy: 0.1249 - val_loss: 21.0846 - val_mae: 2.8621 - val_accuracy: 0.1183\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 24.9238 - mae: 3.0678 - accuracy: 0.1225 - val_loss: 21.3820 - val_mae: 2.8372 - val_accuracy: 0.1202\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.8362 - mae: 3.0473 - accuracy: 0.1226 - val_loss: 21.5643 - val_mae: 2.7866 - val_accuracy: 0.1190\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.0264 - mae: 3.0157 - accuracy: 0.1259 - val_loss: 20.5608 - val_mae: 2.7610 - val_accuracy: 0.1194\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 23.3886 - mae: 2.9609 - accuracy: 0.1241 - val_loss: 20.0490 - val_mae: 2.7668 - val_accuracy: 0.1194\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 23.1155 - mae: 2.9594 - accuracy: 0.1250 - val_loss: 24.9724 - val_mae: 3.1772 - val_accuracy: 0.1202\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 23.3814 - mae: 2.9766 - accuracy: 0.1260 - val_loss: 19.5990 - val_mae: 2.7939 - val_accuracy: 0.1186\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.4231 - mae: 2.9123 - accuracy: 0.1227 - val_loss: 19.8480 - val_mae: 2.7191 - val_accuracy: 0.1202\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.5362 - mae: 2.9062 - accuracy: 0.1238 - val_loss: 20.0136 - val_mae: 2.7463 - val_accuracy: 0.1198\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.9991 - mae: 2.8819 - accuracy: 0.1240 - val_loss: 19.7923 - val_mae: 2.7591 - val_accuracy: 0.1202\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 22.0985 - mae: 2.8841 - accuracy: 0.1235 - val_loss: 20.1603 - val_mae: 2.6666 - val_accuracy: 0.1202\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 22.1199 - mae: 2.8838 - accuracy: 0.1249 - val_loss: 18.8467 - val_mae: 2.7230 - val_accuracy: 0.1198\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 21.3970 - mae: 2.8331 - accuracy: 0.1226 - val_loss: 18.5533 - val_mae: 2.6258 - val_accuracy: 0.1198\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.6133 - mae: 2.8446 - accuracy: 0.1245 - val_loss: 18.2408 - val_mae: 2.6659 - val_accuracy: 0.1206\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.1653 - mae: 2.8223 - accuracy: 0.1233 - val_loss: 18.6106 - val_mae: 2.6291 - val_accuracy: 0.1198\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 21.2178 - mae: 2.8063 - accuracy: 0.1239 - val_loss: 17.7705 - val_mae: 2.6602 - val_accuracy: 0.1179\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 21.0553 - mae: 2.7896 - accuracy: 0.1239 - val_loss: 17.5405 - val_mae: 2.5885 - val_accuracy: 0.1202\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.6581 - mae: 2.7799 - accuracy: 0.1232 - val_loss: 17.6138 - val_mae: 2.5770 - val_accuracy: 0.1198\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.9582 - mae: 2.7751 - accuracy: 0.1250 - val_loss: 18.5843 - val_mae: 2.6894 - val_accuracy: 0.1202\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.2790 - mae: 2.7585 - accuracy: 0.1244 - val_loss: 17.7214 - val_mae: 2.5344 - val_accuracy: 0.1194\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.3794 - mae: 2.7290 - accuracy: 0.1239 - val_loss: 17.4085 - val_mae: 2.5285 - val_accuracy: 0.1210\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.1549 - mae: 2.7225 - accuracy: 0.1243 - val_loss: 17.0127 - val_mae: 2.5545 - val_accuracy: 0.1206\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 20.2205 - mae: 2.7314 - accuracy: 0.1256 - val_loss: 17.2470 - val_mae: 2.5173 - val_accuracy: 0.1213\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 19.3997 - mae: 2.6849 - accuracy: 0.1245 - val_loss: 16.8419 - val_mae: 2.5390 - val_accuracy: 0.1213\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.3905 - mae: 2.6693 - accuracy: 0.1251 - val_loss: 16.7677 - val_mae: 2.5060 - val_accuracy: 0.1206\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.4309 - mae: 2.6557 - accuracy: 0.1253 - val_loss: 18.0476 - val_mae: 2.6469 - val_accuracy: 0.1217\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.1496 - mae: 2.6605 - accuracy: 0.1262 - val_loss: 17.3790 - val_mae: 2.4950 - val_accuracy: 0.1217\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 18.8230 - mae: 2.6533 - accuracy: 0.1237 - val_loss: 18.2038 - val_mae: 2.5196 - val_accuracy: 0.1221\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.0807 - mae: 2.6381 - accuracy: 0.1253 - val_loss: 16.0193 - val_mae: 2.4805 - val_accuracy: 0.1213\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.5053 - mae: 2.6456 - accuracy: 0.1255 - val_loss: 16.2708 - val_mae: 2.4584 - val_accuracy: 0.1213\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.5861 - mae: 2.6124 - accuracy: 0.1244 - val_loss: 17.2141 - val_mae: 2.5448 - val_accuracy: 0.1217\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.4660 - mae: 2.6308 - accuracy: 0.1252 - val_loss: 16.1541 - val_mae: 2.4627 - val_accuracy: 0.1206\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.4783 - mae: 2.6228 - accuracy: 0.1243 - val_loss: 15.9888 - val_mae: 2.4649 - val_accuracy: 0.1225\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.5378 - mae: 2.6221 - accuracy: 0.1270 - val_loss: 17.4893 - val_mae: 2.4777 - val_accuracy: 0.1217\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.4762 - mae: 2.6016 - accuracy: 0.1270 - val_loss: 16.8432 - val_mae: 2.4361 - val_accuracy: 0.1217\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.8391 - mae: 2.5650 - accuracy: 0.1250 - val_loss: 15.9705 - val_mae: 2.4354 - val_accuracy: 0.1213\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.5164 - mae: 2.5598 - accuracy: 0.1263 - val_loss: 16.2554 - val_mae: 2.4729 - val_accuracy: 0.1202\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.0949 - mae: 2.5776 - accuracy: 0.1262 - val_loss: 15.4246 - val_mae: 2.3918 - val_accuracy: 0.1221\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.9089 - mae: 2.5691 - accuracy: 0.1263 - val_loss: 15.9776 - val_mae: 2.4178 - val_accuracy: 0.1217\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.8357 - mae: 2.5704 - accuracy: 0.1268 - val_loss: 15.6201 - val_mae: 2.4495 - val_accuracy: 0.1206\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.6479 - mae: 2.5378 - accuracy: 0.1269 - val_loss: 15.4364 - val_mae: 2.4074 - val_accuracy: 0.1206\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 17.4541 - mae: 2.5566 - accuracy: 0.1262 - val_loss: 15.7303 - val_mae: 2.3704 - val_accuracy: 0.1213\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.1837 - mae: 2.5287 - accuracy: 0.1264 - val_loss: 15.0692 - val_mae: 2.3439 - val_accuracy: 0.1190\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.2260 - mae: 2.5189 - accuracy: 0.1226 - val_loss: 15.6301 - val_mae: 2.3498 - val_accuracy: 0.1217\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.4808 - mae: 2.5265 - accuracy: 0.1250 - val_loss: 14.9772 - val_mae: 2.3343 - val_accuracy: 0.1202\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.8614 - mae: 2.4966 - accuracy: 0.1252 - val_loss: 16.5157 - val_mae: 2.4007 - val_accuracy: 0.1159\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 17.1444 - mae: 2.5099 - accuracy: 0.1241 - val_loss: 14.6964 - val_mae: 2.3246 - val_accuracy: 0.1163\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.3220 - mae: 2.5293 - accuracy: 0.1258 - val_loss: 15.1232 - val_mae: 2.3275 - val_accuracy: 0.1163\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.8550 - mae: 2.4943 - accuracy: 0.1275 - val_loss: 14.7846 - val_mae: 2.3188 - val_accuracy: 0.1202\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.0944 - mae: 2.4954 - accuracy: 0.1250 - val_loss: 15.0131 - val_mae: 2.3847 - val_accuracy: 0.1233\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.3056 - mae: 2.4680 - accuracy: 0.1270 - val_loss: 14.9064 - val_mae: 2.3134 - val_accuracy: 0.1221\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 16.3706 - mae: 2.4631 - accuracy: 0.1249 - val_loss: 14.3623 - val_mae: 2.3215 - val_accuracy: 0.1144\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.9199 - mae: 2.4991 - accuracy: 0.1258 - val_loss: 14.5310 - val_mae: 2.3122 - val_accuracy: 0.1233\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.7484 - mae: 2.4615 - accuracy: 0.1272 - val_loss: 16.1805 - val_mae: 2.3647 - val_accuracy: 0.1237\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.3330 - mae: 2.4587 - accuracy: 0.1274 - val_loss: 15.4438 - val_mae: 2.3854 - val_accuracy: 0.1225\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 16.6866 - mae: 2.4699 - accuracy: 0.1255 - val_loss: 14.2889 - val_mae: 2.2875 - val_accuracy: 0.1229\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.2875 - mae: 2.4435 - accuracy: 0.1250 - val_loss: 14.4717 - val_mae: 2.3173 - val_accuracy: 0.1233\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 16.1891 - mae: 2.4482 - accuracy: 0.1261 - val_loss: 16.7965 - val_mae: 2.4540 - val_accuracy: 0.1237\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 16.2299 - mae: 2.4231 - accuracy: 0.1275 - val_loss: 15.5488 - val_mae: 2.3859 - val_accuracy: 0.1237\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.3190 - mae: 2.4248 - accuracy: 0.1276 - val_loss: 15.0106 - val_mae: 2.3565 - val_accuracy: 0.1233\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.4878 - mae: 2.4016 - accuracy: 0.1259 - val_loss: 14.3733 - val_mae: 2.2641 - val_accuracy: 0.1233\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.5255 - mae: 2.3950 - accuracy: 0.1276 - val_loss: 14.2852 - val_mae: 2.2549 - val_accuracy: 0.1252\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 15.9745 - mae: 2.4073 - accuracy: 0.1286 - val_loss: 14.1489 - val_mae: 2.2846 - val_accuracy: 0.1248\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.0703 - mae: 2.4171 - accuracy: 0.1244 - val_loss: 14.1993 - val_mae: 2.2782 - val_accuracy: 0.1233\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.8111 - mae: 2.4034 - accuracy: 0.1276 - val_loss: 13.9911 - val_mae: 2.2771 - val_accuracy: 0.1240\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 15.7778 - mae: 2.4082 - accuracy: 0.1252 - val_loss: 14.3706 - val_mae: 2.2543 - val_accuracy: 0.1233\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 16.0516 - mae: 2.4009 - accuracy: 0.1276 - val_loss: 14.2219 - val_mae: 2.2976 - val_accuracy: 0.1225\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.7643 - mae: 2.3837 - accuracy: 0.1265 - val_loss: 14.1515 - val_mae: 2.2369 - val_accuracy: 0.1167\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.6834 - mae: 2.3830 - accuracy: 0.1262 - val_loss: 14.2737 - val_mae: 2.2506 - val_accuracy: 0.1198\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.0920 - mae: 2.3439 - accuracy: 0.1258 - val_loss: 14.6029 - val_mae: 2.3153 - val_accuracy: 0.1240\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.0083 - mae: 2.3391 - accuracy: 0.1260 - val_loss: 14.1459 - val_mae: 2.2479 - val_accuracy: 0.1240\n",
      "Kappa Score: 0.9029313102818606\n",
      "\n",
      "--------Fold 2--------\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_144 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_145 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_72\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_144 (LSTM)             (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_145 (LSTM)             (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_72 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 9s 23ms/step - loss: 78.5176 - mae: 5.1290 - accuracy: 0.1194 - val_loss: 65.7531 - val_mae: 4.6306 - val_accuracy: 0.1121\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 55.8039 - mae: 4.4479 - accuracy: 0.1100 - val_loss: 55.2302 - val_mae: 4.2251 - val_accuracy: 0.0952\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 48.8567 - mae: 4.2752 - accuracy: 0.0930 - val_loss: 48.9331 - val_mae: 4.1381 - val_accuracy: 0.0871\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 45.8199 - mae: 4.2319 - accuracy: 0.0913 - val_loss: 45.8964 - val_mae: 4.0656 - val_accuracy: 0.0852\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 44.3470 - mae: 4.1761 - accuracy: 0.0911 - val_loss: 44.2291 - val_mae: 3.9753 - val_accuracy: 0.0886\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 43.1705 - mae: 4.0826 - accuracy: 0.0964 - val_loss: 42.1308 - val_mae: 3.9226 - val_accuracy: 0.0967\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 42.2490 - mae: 4.0306 - accuracy: 0.0996 - val_loss: 41.4365 - val_mae: 3.8083 - val_accuracy: 0.0998\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 41.5286 - mae: 3.9848 - accuracy: 0.1033 - val_loss: 40.4257 - val_mae: 3.7000 - val_accuracy: 0.1029\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 41.1172 - mae: 3.9235 - accuracy: 0.1115 - val_loss: 39.6113 - val_mae: 3.6187 - val_accuracy: 0.1145\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 41.2348 - mae: 3.8777 - accuracy: 0.1264 - val_loss: 39.1768 - val_mae: 3.5618 - val_accuracy: 0.1214\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 38.9170 - mae: 3.7647 - accuracy: 0.1328 - val_loss: 37.4870 - val_mae: 3.5139 - val_accuracy: 0.1237\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 38.4620 - mae: 3.7184 - accuracy: 0.1351 - val_loss: 36.8372 - val_mae: 3.4648 - val_accuracy: 0.1256\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 37.5634 - mae: 3.6627 - accuracy: 0.1358 - val_loss: 37.0169 - val_mae: 3.4027 - val_accuracy: 0.1256\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 37.5215 - mae: 3.6722 - accuracy: 0.1353 - val_loss: 34.8899 - val_mae: 3.3527 - val_accuracy: 0.1260\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 36.9151 - mae: 3.6073 - accuracy: 0.1355 - val_loss: 34.2672 - val_mae: 3.3001 - val_accuracy: 0.1256\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 35.3324 - mae: 3.5106 - accuracy: 0.1355 - val_loss: 34.2954 - val_mae: 3.2559 - val_accuracy: 0.1260\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 3s 21ms/step - loss: 35.3814 - mae: 3.5076 - accuracy: 0.1354 - val_loss: 34.6007 - val_mae: 3.2343 - val_accuracy: 0.1249\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 34.1566 - mae: 3.4512 - accuracy: 0.1345 - val_loss: 31.3262 - val_mae: 3.2543 - val_accuracy: 0.1245\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 33.3255 - mae: 3.4033 - accuracy: 0.1346 - val_loss: 32.1611 - val_mae: 3.1607 - val_accuracy: 0.1233\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 3s 21ms/step - loss: 32.7775 - mae: 3.3852 - accuracy: 0.1340 - val_loss: 34.0089 - val_mae: 3.1785 - val_accuracy: 0.1233\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 31.5750 - mae: 3.3284 - accuracy: 0.1337 - val_loss: 28.8320 - val_mae: 3.1564 - val_accuracy: 0.1229\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 4s 22ms/step - loss: 30.4649 - mae: 3.2841 - accuracy: 0.1333 - val_loss: 28.1200 - val_mae: 3.0821 - val_accuracy: 0.1218\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 30.4121 - mae: 3.2442 - accuracy: 0.1324 - val_loss: 27.8136 - val_mae: 3.0192 - val_accuracy: 0.1218\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 29.6898 - mae: 3.2243 - accuracy: 0.1319 - val_loss: 27.8051 - val_mae: 2.9821 - val_accuracy: 0.1222\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 28.2458 - mae: 3.1324 - accuracy: 0.1327 - val_loss: 26.5534 - val_mae: 2.9940 - val_accuracy: 0.1233\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 28.5446 - mae: 3.1520 - accuracy: 0.1324 - val_loss: 26.8717 - val_mae: 2.9183 - val_accuracy: 0.1206\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 27.3127 - mae: 3.1009 - accuracy: 0.1315 - val_loss: 25.5032 - val_mae: 2.8964 - val_accuracy: 0.1214\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 26.9576 - mae: 3.0557 - accuracy: 0.1313 - val_loss: 24.7439 - val_mae: 2.9026 - val_accuracy: 0.1222\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 26.4380 - mae: 3.0495 - accuracy: 0.1310 - val_loss: 24.6599 - val_mae: 2.8566 - val_accuracy: 0.1229\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 26.3104 - mae: 3.0185 - accuracy: 0.1312 - val_loss: 23.7242 - val_mae: 2.8431 - val_accuracy: 0.1229\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 25.7737 - mae: 2.9680 - accuracy: 0.1308 - val_loss: 25.1526 - val_mae: 2.7756 - val_accuracy: 0.1210\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 25.7350 - mae: 2.9870 - accuracy: 0.1315 - val_loss: 25.4168 - val_mae: 2.7937 - val_accuracy: 0.1206\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 24.8087 - mae: 2.9388 - accuracy: 0.1314 - val_loss: 23.2562 - val_mae: 2.7173 - val_accuracy: 0.1214\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 24.1779 - mae: 2.9029 - accuracy: 0.1313 - val_loss: 22.0030 - val_mae: 2.7005 - val_accuracy: 0.1222\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.8148 - mae: 2.9222 - accuracy: 0.1326 - val_loss: 21.6664 - val_mae: 2.7058 - val_accuracy: 0.1222\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 23.3184 - mae: 2.8414 - accuracy: 0.1320 - val_loss: 22.6069 - val_mae: 2.6811 - val_accuracy: 0.1210\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 24.2207 - mae: 2.8831 - accuracy: 0.1322 - val_loss: 22.3133 - val_mae: 2.6410 - val_accuracy: 0.1218\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 23.9640 - mae: 2.8837 - accuracy: 0.1323 - val_loss: 21.5200 - val_mae: 2.6281 - val_accuracy: 0.1214\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 23.3838 - mae: 2.8173 - accuracy: 0.1311 - val_loss: 20.9442 - val_mae: 2.6389 - val_accuracy: 0.1214\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 23.3755 - mae: 2.8366 - accuracy: 0.1321 - val_loss: 20.9675 - val_mae: 2.6241 - val_accuracy: 0.1218\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 22.4773 - mae: 2.7936 - accuracy: 0.1324 - val_loss: 20.3765 - val_mae: 2.6033 - val_accuracy: 0.1222\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 22.7003 - mae: 2.7611 - accuracy: 0.1329 - val_loss: 20.5400 - val_mae: 2.6965 - val_accuracy: 0.1229\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.0468 - mae: 2.7630 - accuracy: 0.1317 - val_loss: 20.2322 - val_mae: 2.6734 - val_accuracy: 0.1222\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 22.6857 - mae: 2.7889 - accuracy: 0.1315 - val_loss: 19.8565 - val_mae: 2.5369 - val_accuracy: 0.1225\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 22.2677 - mae: 2.7314 - accuracy: 0.1323 - val_loss: 20.0293 - val_mae: 2.5252 - val_accuracy: 0.1229\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 21.3703 - mae: 2.7073 - accuracy: 0.1329 - val_loss: 19.6721 - val_mae: 2.4974 - val_accuracy: 0.1225\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 21.1864 - mae: 2.6992 - accuracy: 0.1328 - val_loss: 19.9334 - val_mae: 2.5037 - val_accuracy: 0.1225\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 21.2233 - mae: 2.7028 - accuracy: 0.1321 - val_loss: 19.5903 - val_mae: 2.4861 - val_accuracy: 0.1225\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 20.2790 - mae: 2.6437 - accuracy: 0.1312 - val_loss: 19.0721 - val_mae: 2.4523 - val_accuracy: 0.1229\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 20.6810 - mae: 2.6655 - accuracy: 0.1314 - val_loss: 19.1384 - val_mae: 2.4642 - val_accuracy: 0.1222\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 20.2800 - mae: 2.6398 - accuracy: 0.1324 - val_loss: 18.6421 - val_mae: 2.5260 - val_accuracy: 0.1225\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 20.1204 - mae: 2.6556 - accuracy: 0.1321 - val_loss: 18.2442 - val_mae: 2.4770 - val_accuracy: 0.1206\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 20.3851 - mae: 2.6385 - accuracy: 0.1315 - val_loss: 19.9384 - val_mae: 2.6899 - val_accuracy: 0.1218\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.7610 - mae: 2.5892 - accuracy: 0.1312 - val_loss: 18.5017 - val_mae: 2.4167 - val_accuracy: 0.1225\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 19.9069 - mae: 2.6055 - accuracy: 0.1326 - val_loss: 17.9263 - val_mae: 2.4492 - val_accuracy: 0.1198\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 19.5175 - mae: 2.5795 - accuracy: 0.1309 - val_loss: 17.6331 - val_mae: 2.4109 - val_accuracy: 0.1206\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.9718 - mae: 2.5432 - accuracy: 0.1313 - val_loss: 18.1159 - val_mae: 2.3733 - val_accuracy: 0.1218\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 18.9062 - mae: 2.5566 - accuracy: 0.1304 - val_loss: 17.6274 - val_mae: 2.3527 - val_accuracy: 0.1206\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.6992 - mae: 2.5329 - accuracy: 0.1306 - val_loss: 17.2906 - val_mae: 2.3382 - val_accuracy: 0.1206\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.4764 - mae: 2.5721 - accuracy: 0.1301 - val_loss: 17.7814 - val_mae: 2.3654 - val_accuracy: 0.1214\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 18.1674 - mae: 2.5115 - accuracy: 0.1306 - val_loss: 17.0037 - val_mae: 2.3504 - val_accuracy: 0.1202\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.1405 - mae: 2.5126 - accuracy: 0.1311 - val_loss: 17.9000 - val_mae: 2.3428 - val_accuracy: 0.1214\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 3s 21ms/step - loss: 18.3788 - mae: 2.5021 - accuracy: 0.1308 - val_loss: 16.9517 - val_mae: 2.3957 - val_accuracy: 0.1214\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.1315 - mae: 2.4800 - accuracy: 0.1306 - val_loss: 16.6035 - val_mae: 2.3551 - val_accuracy: 0.1210\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 17.7662 - mae: 2.4738 - accuracy: 0.1313 - val_loss: 16.1502 - val_mae: 2.2840 - val_accuracy: 0.1214\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 18.0557 - mae: 2.4995 - accuracy: 0.1301 - val_loss: 17.6435 - val_mae: 2.3369 - val_accuracy: 0.1210\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.5415 - mae: 2.4559 - accuracy: 0.1298 - val_loss: 16.5287 - val_mae: 2.3044 - val_accuracy: 0.1206\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.7859 - mae: 2.4695 - accuracy: 0.1298 - val_loss: 17.6499 - val_mae: 2.3119 - val_accuracy: 0.1214\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 17.5242 - mae: 2.4557 - accuracy: 0.1293 - val_loss: 16.0969 - val_mae: 2.2703 - val_accuracy: 0.1206\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.4934 - mae: 2.4529 - accuracy: 0.1299 - val_loss: 15.9046 - val_mae: 2.2645 - val_accuracy: 0.1202\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 17.8060 - mae: 2.4533 - accuracy: 0.1282 - val_loss: 16.0943 - val_mae: 2.2953 - val_accuracy: 0.1202\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 16.8623 - mae: 2.4352 - accuracy: 0.1300 - val_loss: 17.0619 - val_mae: 2.3991 - val_accuracy: 0.1202\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.8465 - mae: 2.4544 - accuracy: 0.1297 - val_loss: 15.8474 - val_mae: 2.2406 - val_accuracy: 0.1210\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.3856 - mae: 2.4291 - accuracy: 0.1303 - val_loss: 15.8739 - val_mae: 2.2213 - val_accuracy: 0.1214\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 16.8446 - mae: 2.4038 - accuracy: 0.1300 - val_loss: 17.0134 - val_mae: 2.3138 - val_accuracy: 0.1206\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 16.9598 - mae: 2.4105 - accuracy: 0.1290 - val_loss: 15.7024 - val_mae: 2.2343 - val_accuracy: 0.1214\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.8616 - mae: 2.3989 - accuracy: 0.1300 - val_loss: 16.0468 - val_mae: 2.3036 - val_accuracy: 0.1222\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.8277 - mae: 2.4141 - accuracy: 0.1300 - val_loss: 16.7436 - val_mae: 2.3762 - val_accuracy: 0.1222\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 16.2189 - mae: 2.3780 - accuracy: 0.1292 - val_loss: 15.8627 - val_mae: 2.2666 - val_accuracy: 0.1214\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 16.7261 - mae: 2.3981 - accuracy: 0.1300 - val_loss: 16.3186 - val_mae: 2.2264 - val_accuracy: 0.1214\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.9903 - mae: 2.3549 - accuracy: 0.1294 - val_loss: 16.3270 - val_mae: 2.2176 - val_accuracy: 0.1218\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.1811 - mae: 2.3476 - accuracy: 0.1305 - val_loss: 15.0442 - val_mae: 2.2156 - val_accuracy: 0.1218\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.9594 - mae: 2.3477 - accuracy: 0.1286 - val_loss: 15.1019 - val_mae: 2.1944 - val_accuracy: 0.1218\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.4654 - mae: 2.3209 - accuracy: 0.1299 - val_loss: 15.0857 - val_mae: 2.2266 - val_accuracy: 0.1214\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 15.8546 - mae: 2.3387 - accuracy: 0.1301 - val_loss: 15.6399 - val_mae: 2.2016 - val_accuracy: 0.1222\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.3757 - mae: 2.3752 - accuracy: 0.1297 - val_loss: 15.2107 - val_mae: 2.1851 - val_accuracy: 0.1225\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 15.8544 - mae: 2.3304 - accuracy: 0.1295 - val_loss: 15.6580 - val_mae: 2.1713 - val_accuracy: 0.1218\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.8260 - mae: 2.3267 - accuracy: 0.1311 - val_loss: 14.6724 - val_mae: 2.1875 - val_accuracy: 0.1237\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.2552 - mae: 2.2927 - accuracy: 0.1300 - val_loss: 14.7669 - val_mae: 2.1484 - val_accuracy: 0.1237\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.3590 - mae: 2.3036 - accuracy: 0.1305 - val_loss: 15.2728 - val_mae: 2.2428 - val_accuracy: 0.1233\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 15.5380 - mae: 2.3090 - accuracy: 0.1309 - val_loss: 15.0392 - val_mae: 2.1847 - val_accuracy: 0.1229\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.0620 - mae: 2.2884 - accuracy: 0.1299 - val_loss: 14.8015 - val_mae: 2.1786 - val_accuracy: 0.1225\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 14.8854 - mae: 2.2746 - accuracy: 0.1297 - val_loss: 14.8628 - val_mae: 2.1712 - val_accuracy: 0.1241\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.1409 - mae: 2.2775 - accuracy: 0.1306 - val_loss: 14.8618 - val_mae: 2.1887 - val_accuracy: 0.1222\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.0883 - mae: 2.2769 - accuracy: 0.1296 - val_loss: 14.6670 - val_mae: 2.1992 - val_accuracy: 0.1225\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.0347 - mae: 2.2764 - accuracy: 0.1292 - val_loss: 14.5779 - val_mae: 2.1513 - val_accuracy: 0.1218\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.0148 - mae: 2.2716 - accuracy: 0.1293 - val_loss: 16.8242 - val_mae: 2.2421 - val_accuracy: 0.1222\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.9621 - mae: 2.2524 - accuracy: 0.1306 - val_loss: 14.6273 - val_mae: 2.1651 - val_accuracy: 0.1225\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.0142 - mae: 2.2598 - accuracy: 0.1286 - val_loss: 15.2369 - val_mae: 2.2467 - val_accuracy: 0.1233\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 14.8490 - mae: 2.2600 - accuracy: 0.1300 - val_loss: 14.8277 - val_mae: 2.1785 - val_accuracy: 0.1229\n",
      "Kappa Score: 0.9068350430303649\n",
      "\n",
      "--------Fold 3--------\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_146 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_147 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_73\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_146 (LSTM)             (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_147 (LSTM)             (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_73 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 8s 27ms/step - loss: 80.7494 - mae: 5.3301 - accuracy: 0.1181 - val_loss: 64.6667 - val_mae: 4.8567 - val_accuracy: 0.1121\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 64.4435 - mae: 4.9942 - accuracy: 0.1176 - val_loss: 56.3967 - val_mae: 4.6241 - val_accuracy: 0.1033\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 58.1746 - mae: 4.8201 - accuracy: 0.1113 - val_loss: 50.8857 - val_mae: 4.4224 - val_accuracy: 0.1025\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 55.0923 - mae: 4.7341 - accuracy: 0.1091 - val_loss: 47.9410 - val_mae: 4.2913 - val_accuracy: 0.1052\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 53.4127 - mae: 4.6476 - accuracy: 0.1140 - val_loss: 44.6501 - val_mae: 4.1599 - val_accuracy: 0.1114\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 50.4292 - mae: 4.5162 - accuracy: 0.1156 - val_loss: 41.9099 - val_mae: 4.0640 - val_accuracy: 0.1160\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 47.7802 - mae: 4.4044 - accuracy: 0.1149 - val_loss: 38.6338 - val_mae: 3.9032 - val_accuracy: 0.1160\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 45.2144 - mae: 4.2811 - accuracy: 0.1192 - val_loss: 37.3540 - val_mae: 3.6586 - val_accuracy: 0.1225\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 44.2970 - mae: 4.2079 - accuracy: 0.1206 - val_loss: 35.1727 - val_mae: 3.7244 - val_accuracy: 0.1256\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 41.5848 - mae: 4.0525 - accuracy: 0.1254 - val_loss: 33.2619 - val_mae: 3.4077 - val_accuracy: 0.1249\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 40.2080 - mae: 3.9733 - accuracy: 0.1276 - val_loss: 30.4500 - val_mae: 3.3408 - val_accuracy: 0.1241\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 37.6229 - mae: 3.8488 - accuracy: 0.1272 - val_loss: 28.8562 - val_mae: 3.2524 - val_accuracy: 0.1245\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 35.6267 - mae: 3.7009 - accuracy: 0.1285 - val_loss: 29.9634 - val_mae: 3.1741 - val_accuracy: 0.1245\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 34.1803 - mae: 3.6194 - accuracy: 0.1268 - val_loss: 26.2405 - val_mae: 3.1684 - val_accuracy: 0.1256\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 32.3372 - mae: 3.5275 - accuracy: 0.1252 - val_loss: 26.0097 - val_mae: 3.0881 - val_accuracy: 0.1237\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 32.7710 - mae: 3.5322 - accuracy: 0.1245 - val_loss: 26.8333 - val_mae: 3.0472 - val_accuracy: 0.1222\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 31.5482 - mae: 3.4492 - accuracy: 0.1255 - val_loss: 24.9703 - val_mae: 3.0785 - val_accuracy: 0.1222\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 29.5587 - mae: 3.4001 - accuracy: 0.1225 - val_loss: 27.0211 - val_mae: 3.0128 - val_accuracy: 0.1222\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 29.0742 - mae: 3.3208 - accuracy: 0.1213 - val_loss: 25.5912 - val_mae: 2.9817 - val_accuracy: 0.1202\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 29.4062 - mae: 3.3482 - accuracy: 0.1216 - val_loss: 24.3546 - val_mae: 3.1108 - val_accuracy: 0.1202\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 27.8494 - mae: 3.2871 - accuracy: 0.1199 - val_loss: 24.3555 - val_mae: 3.1235 - val_accuracy: 0.1191\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 27.7785 - mae: 3.2868 - accuracy: 0.1203 - val_loss: 23.5698 - val_mae: 2.9568 - val_accuracy: 0.1210\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 27.0205 - mae: 3.2309 - accuracy: 0.1200 - val_loss: 22.7948 - val_mae: 2.9345 - val_accuracy: 0.1206\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 26.3004 - mae: 3.1874 - accuracy: 0.1197 - val_loss: 22.9647 - val_mae: 2.9874 - val_accuracy: 0.1198\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 26.2938 - mae: 3.1804 - accuracy: 0.1207 - val_loss: 23.6276 - val_mae: 2.8965 - val_accuracy: 0.1195\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.5381 - mae: 3.1525 - accuracy: 0.1201 - val_loss: 22.1795 - val_mae: 2.9218 - val_accuracy: 0.1195\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.5407 - mae: 3.1425 - accuracy: 0.1200 - val_loss: 22.6294 - val_mae: 2.9031 - val_accuracy: 0.1206\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.6547 - mae: 3.1429 - accuracy: 0.1193 - val_loss: 22.9028 - val_mae: 2.8521 - val_accuracy: 0.1202\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 25.2812 - mae: 3.1120 - accuracy: 0.1200 - val_loss: 21.5556 - val_mae: 2.8091 - val_accuracy: 0.1191\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 23.8513 - mae: 3.0318 - accuracy: 0.1202 - val_loss: 21.1523 - val_mae: 2.8394 - val_accuracy: 0.1191\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 24.3711 - mae: 3.0756 - accuracy: 0.1187 - val_loss: 21.2675 - val_mae: 2.8467 - val_accuracy: 0.1191\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 23.0740 - mae: 3.0005 - accuracy: 0.1192 - val_loss: 21.7198 - val_mae: 2.8221 - val_accuracy: 0.1198\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.3151 - mae: 3.0469 - accuracy: 0.1182 - val_loss: 20.9789 - val_mae: 2.7896 - val_accuracy: 0.1206\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 23.6708 - mae: 2.9917 - accuracy: 0.1197 - val_loss: 21.0242 - val_mae: 2.7923 - val_accuracy: 0.1198\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 23.1599 - mae: 2.9829 - accuracy: 0.1189 - val_loss: 21.1401 - val_mae: 2.7555 - val_accuracy: 0.1202\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 22.6860 - mae: 2.9531 - accuracy: 0.1197 - val_loss: 20.6448 - val_mae: 2.7557 - val_accuracy: 0.1195\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.3535 - mae: 2.9276 - accuracy: 0.1224 - val_loss: 20.1385 - val_mae: 2.7479 - val_accuracy: 0.1191\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 21.5772 - mae: 2.8999 - accuracy: 0.1193 - val_loss: 20.8565 - val_mae: 2.7042 - val_accuracy: 0.1191\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.0789 - mae: 2.9099 - accuracy: 0.1197 - val_loss: 19.2298 - val_mae: 2.6872 - val_accuracy: 0.1179\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.5878 - mae: 2.8768 - accuracy: 0.1203 - val_loss: 19.0759 - val_mae: 2.6841 - val_accuracy: 0.1187\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 21.5283 - mae: 2.8860 - accuracy: 0.1201 - val_loss: 19.6519 - val_mae: 2.6584 - val_accuracy: 0.1179\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 21.0604 - mae: 2.8272 - accuracy: 0.1207 - val_loss: 19.3491 - val_mae: 2.7084 - val_accuracy: 0.1202\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 20.7871 - mae: 2.8142 - accuracy: 0.1219 - val_loss: 18.7216 - val_mae: 2.6451 - val_accuracy: 0.1191\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.4234 - mae: 2.8410 - accuracy: 0.1184 - val_loss: 19.2448 - val_mae: 2.6309 - val_accuracy: 0.1198\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.1826 - mae: 2.7775 - accuracy: 0.1213 - val_loss: 20.2389 - val_mae: 2.8507 - val_accuracy: 0.1195\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.3406 - mae: 2.7742 - accuracy: 0.1215 - val_loss: 18.2588 - val_mae: 2.6388 - val_accuracy: 0.1198\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.2630 - mae: 2.7778 - accuracy: 0.1205 - val_loss: 18.5655 - val_mae: 2.6984 - val_accuracy: 0.1206\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 19.5490 - mae: 2.7166 - accuracy: 0.1201 - val_loss: 18.9166 - val_mae: 2.7032 - val_accuracy: 0.1218\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.4454 - mae: 2.7209 - accuracy: 0.1202 - val_loss: 17.7270 - val_mae: 2.6073 - val_accuracy: 0.1210\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.3864 - mae: 2.7070 - accuracy: 0.1215 - val_loss: 17.8383 - val_mae: 2.6337 - val_accuracy: 0.1218\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.4291 - mae: 2.7041 - accuracy: 0.1223 - val_loss: 18.2903 - val_mae: 2.6448 - val_accuracy: 0.1214\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 19.2666 - mae: 2.6779 - accuracy: 0.1221 - val_loss: 17.8548 - val_mae: 2.5293 - val_accuracy: 0.1225\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.4809 - mae: 2.6507 - accuracy: 0.1225 - val_loss: 18.3729 - val_mae: 2.5167 - val_accuracy: 0.1241\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.7506 - mae: 2.6623 - accuracy: 0.1219 - val_loss: 17.3742 - val_mae: 2.5160 - val_accuracy: 0.1225\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 19.1233 - mae: 2.6901 - accuracy: 0.1229 - val_loss: 16.9872 - val_mae: 2.5023 - val_accuracy: 0.1233\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 18.3842 - mae: 2.6183 - accuracy: 0.1221 - val_loss: 17.2690 - val_mae: 2.4976 - val_accuracy: 0.1222\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 19.2299 - mae: 2.6656 - accuracy: 0.1213 - val_loss: 16.9383 - val_mae: 2.5239 - val_accuracy: 0.1214\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.6396 - mae: 2.5973 - accuracy: 0.1232 - val_loss: 16.7430 - val_mae: 2.5137 - val_accuracy: 0.1222\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.0756 - mae: 2.6200 - accuracy: 0.1224 - val_loss: 17.5355 - val_mae: 2.4601 - val_accuracy: 0.1229\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 17.9265 - mae: 2.5955 - accuracy: 0.1250 - val_loss: 16.6564 - val_mae: 2.5127 - val_accuracy: 0.1225\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 17.7715 - mae: 2.5927 - accuracy: 0.1232 - val_loss: 16.3826 - val_mae: 2.4594 - val_accuracy: 0.1222\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.4977 - mae: 2.5734 - accuracy: 0.1237 - val_loss: 16.5596 - val_mae: 2.4991 - val_accuracy: 0.1225\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.7715 - mae: 2.5868 - accuracy: 0.1253 - val_loss: 16.3540 - val_mae: 2.4454 - val_accuracy: 0.1229\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 17.1623 - mae: 2.5438 - accuracy: 0.1236 - val_loss: 16.3723 - val_mae: 2.4424 - val_accuracy: 0.1225\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.3096 - mae: 2.5624 - accuracy: 0.1240 - val_loss: 17.1270 - val_mae: 2.4385 - val_accuracy: 0.1164\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.2579 - mae: 2.5480 - accuracy: 0.1227 - val_loss: 16.6309 - val_mae: 2.4512 - val_accuracy: 0.1229\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.0330 - mae: 2.5365 - accuracy: 0.1227 - val_loss: 16.3566 - val_mae: 2.4333 - val_accuracy: 0.1237\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 17.0712 - mae: 2.5290 - accuracy: 0.1230 - val_loss: 16.3926 - val_mae: 2.4187 - val_accuracy: 0.1245\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.3883 - mae: 2.5484 - accuracy: 0.1240 - val_loss: 16.6522 - val_mae: 2.4227 - val_accuracy: 0.1256\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 16.5025 - mae: 2.5047 - accuracy: 0.1251 - val_loss: 16.3107 - val_mae: 2.4800 - val_accuracy: 0.1241\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 16.9603 - mae: 2.5318 - accuracy: 0.1229 - val_loss: 16.2393 - val_mae: 2.4868 - val_accuracy: 0.1237\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.6294 - mae: 2.5036 - accuracy: 0.1256 - val_loss: 16.6294 - val_mae: 2.4043 - val_accuracy: 0.1237\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.4021 - mae: 2.4807 - accuracy: 0.1232 - val_loss: 15.9496 - val_mae: 2.3884 - val_accuracy: 0.1249\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 16.7899 - mae: 2.5031 - accuracy: 0.1248 - val_loss: 16.5287 - val_mae: 2.4329 - val_accuracy: 0.1179\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 16.9585 - mae: 2.5196 - accuracy: 0.1236 - val_loss: 16.0780 - val_mae: 2.4012 - val_accuracy: 0.1191\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.9000 - mae: 2.4507 - accuracy: 0.1226 - val_loss: 16.0899 - val_mae: 2.4015 - val_accuracy: 0.1241\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.7365 - mae: 2.4354 - accuracy: 0.1261 - val_loss: 15.8302 - val_mae: 2.4149 - val_accuracy: 0.1183\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.8809 - mae: 2.4454 - accuracy: 0.1247 - val_loss: 17.1570 - val_mae: 2.3934 - val_accuracy: 0.1171\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.8136 - mae: 2.4239 - accuracy: 0.1225 - val_loss: 15.8487 - val_mae: 2.4108 - val_accuracy: 0.1260\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 15.4468 - mae: 2.4264 - accuracy: 0.1233 - val_loss: 17.0589 - val_mae: 2.3816 - val_accuracy: 0.1198\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.6189 - mae: 2.4106 - accuracy: 0.1247 - val_loss: 15.7915 - val_mae: 2.3821 - val_accuracy: 0.1260\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.1888 - mae: 2.4561 - accuracy: 0.1244 - val_loss: 16.2136 - val_mae: 2.3548 - val_accuracy: 0.1198\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.1035 - mae: 2.4434 - accuracy: 0.1246 - val_loss: 15.5866 - val_mae: 2.3648 - val_accuracy: 0.1252\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.7865 - mae: 2.4263 - accuracy: 0.1231 - val_loss: 16.2270 - val_mae: 2.3486 - val_accuracy: 0.1198\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.5314 - mae: 2.4123 - accuracy: 0.1240 - val_loss: 15.9102 - val_mae: 2.4570 - val_accuracy: 0.1260\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.4859 - mae: 2.4037 - accuracy: 0.1237 - val_loss: 15.3601 - val_mae: 2.3343 - val_accuracy: 0.1268\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.6005 - mae: 2.4146 - accuracy: 0.1245 - val_loss: 17.0049 - val_mae: 2.3551 - val_accuracy: 0.1195\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.3759 - mae: 2.3783 - accuracy: 0.1237 - val_loss: 15.8065 - val_mae: 2.3812 - val_accuracy: 0.1264\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.5397 - mae: 2.3999 - accuracy: 0.1254 - val_loss: 15.7581 - val_mae: 2.3893 - val_accuracy: 0.1268\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.0485 - mae: 2.3821 - accuracy: 0.1259 - val_loss: 17.3578 - val_mae: 2.3701 - val_accuracy: 0.1202\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 15.5618 - mae: 2.4158 - accuracy: 0.1255 - val_loss: 16.1878 - val_mae: 2.4280 - val_accuracy: 0.1268\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.1111 - mae: 2.3678 - accuracy: 0.1256 - val_loss: 16.7031 - val_mae: 2.3390 - val_accuracy: 0.1206\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 14.8385 - mae: 2.3516 - accuracy: 0.1262 - val_loss: 16.2514 - val_mae: 2.3251 - val_accuracy: 0.1264\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 15.4553 - mae: 2.3908 - accuracy: 0.1254 - val_loss: 15.5980 - val_mae: 2.3051 - val_accuracy: 0.1264\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.7490 - mae: 2.3516 - accuracy: 0.1253 - val_loss: 15.4274 - val_mae: 2.3066 - val_accuracy: 0.1202\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.0902 - mae: 2.3790 - accuracy: 0.1250 - val_loss: 15.1087 - val_mae: 2.3207 - val_accuracy: 0.1202\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 14.6535 - mae: 2.3460 - accuracy: 0.1247 - val_loss: 15.5400 - val_mae: 2.3184 - val_accuracy: 0.1202\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 14.8185 - mae: 2.3553 - accuracy: 0.1252 - val_loss: 15.3470 - val_mae: 2.3367 - val_accuracy: 0.1210\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.8463 - mae: 2.3474 - accuracy: 0.1246 - val_loss: 15.2755 - val_mae: 2.3136 - val_accuracy: 0.1210\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.2556 - mae: 2.3117 - accuracy: 0.1232 - val_loss: 16.0119 - val_mae: 2.3003 - val_accuracy: 0.1276\n",
      "Kappa Score: 0.8841402524341615\n",
      "\n",
      "--------Fold 4--------\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_148 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_149 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_74\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_148 (LSTM)             (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_149 (LSTM)             (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_74 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 9s 22ms/step - loss: 79.8361 - mae: 5.2223 - accuracy: 0.1187 - val_loss: 62.3276 - val_mae: 4.8670 - val_accuracy: 0.1318\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 59.5159 - mae: 4.7369 - accuracy: 0.1096 - val_loss: 53.3327 - val_mae: 4.4461 - val_accuracy: 0.1225\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 54.0917 - mae: 4.5692 - accuracy: 0.1047 - val_loss: 48.7531 - val_mae: 4.3173 - val_accuracy: 0.1148\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 51.2001 - mae: 4.4655 - accuracy: 0.1034 - val_loss: 45.4059 - val_mae: 4.0842 - val_accuracy: 0.1175\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 49.6588 - mae: 4.3957 - accuracy: 0.1054 - val_loss: 43.4754 - val_mae: 3.9692 - val_accuracy: 0.1187\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 48.7350 - mae: 4.3266 - accuracy: 0.1074 - val_loss: 41.6243 - val_mae: 3.8706 - val_accuracy: 0.1225\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 46.8650 - mae: 4.2232 - accuracy: 0.1103 - val_loss: 39.5720 - val_mae: 3.7612 - val_accuracy: 0.1245\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 45.4925 - mae: 4.1540 - accuracy: 0.1156 - val_loss: 38.4038 - val_mae: 3.7762 - val_accuracy: 0.1306\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 43.2932 - mae: 4.0454 - accuracy: 0.1181 - val_loss: 35.3025 - val_mae: 3.4695 - val_accuracy: 0.1329\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 42.5580 - mae: 3.9897 - accuracy: 0.1211 - val_loss: 34.0702 - val_mae: 3.3695 - val_accuracy: 0.1329\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 40.5583 - mae: 3.8633 - accuracy: 0.1227 - val_loss: 31.3180 - val_mae: 3.3273 - val_accuracy: 0.1341\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 38.2279 - mae: 3.7668 - accuracy: 0.1264 - val_loss: 30.4930 - val_mae: 3.1992 - val_accuracy: 0.1345\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 36.5608 - mae: 3.6625 - accuracy: 0.1236 - val_loss: 28.9092 - val_mae: 3.1301 - val_accuracy: 0.1318\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 36.3510 - mae: 3.6463 - accuracy: 0.1242 - val_loss: 27.9715 - val_mae: 3.1065 - val_accuracy: 0.1345\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 34.7460 - mae: 3.5523 - accuracy: 0.1246 - val_loss: 28.0536 - val_mae: 3.0512 - val_accuracy: 0.1360\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 33.4677 - mae: 3.4679 - accuracy: 0.1247 - val_loss: 26.2914 - val_mae: 3.0197 - val_accuracy: 0.1349\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 32.6583 - mae: 3.4263 - accuracy: 0.1236 - val_loss: 27.1864 - val_mae: 2.9996 - val_accuracy: 0.1318\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 31.3215 - mae: 3.3595 - accuracy: 0.1236 - val_loss: 26.5501 - val_mae: 2.9627 - val_accuracy: 0.1326\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 29.3575 - mae: 3.2675 - accuracy: 0.1235 - val_loss: 23.3570 - val_mae: 2.8463 - val_accuracy: 0.1333\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 28.6644 - mae: 3.2266 - accuracy: 0.1234 - val_loss: 22.4118 - val_mae: 2.8455 - val_accuracy: 0.1341\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 28.2967 - mae: 3.1935 - accuracy: 0.1241 - val_loss: 21.5464 - val_mae: 2.7610 - val_accuracy: 0.1345\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 28.2544 - mae: 3.1854 - accuracy: 0.1235 - val_loss: 20.9156 - val_mae: 2.7430 - val_accuracy: 0.1356\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 27.3836 - mae: 3.1231 - accuracy: 0.1229 - val_loss: 21.7765 - val_mae: 2.7301 - val_accuracy: 0.1364\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 26.5075 - mae: 3.0769 - accuracy: 0.1233 - val_loss: 19.8417 - val_mae: 2.6613 - val_accuracy: 0.1368\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 26.7768 - mae: 3.0795 - accuracy: 0.1238 - val_loss: 20.7844 - val_mae: 2.6520 - val_accuracy: 0.1380\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 26.1327 - mae: 3.0485 - accuracy: 0.1241 - val_loss: 19.2604 - val_mae: 2.6227 - val_accuracy: 0.1383\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 24.8274 - mae: 2.9781 - accuracy: 0.1230 - val_loss: 19.1919 - val_mae: 2.6004 - val_accuracy: 0.1368\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 24.7332 - mae: 2.9575 - accuracy: 0.1240 - val_loss: 18.3427 - val_mae: 2.5762 - val_accuracy: 0.1364\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.1926 - mae: 2.9486 - accuracy: 0.1236 - val_loss: 18.7157 - val_mae: 2.6428 - val_accuracy: 0.1376\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 24.0994 - mae: 2.9370 - accuracy: 0.1241 - val_loss: 17.5560 - val_mae: 2.5234 - val_accuracy: 0.1368\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 23.7777 - mae: 2.9138 - accuracy: 0.1242 - val_loss: 17.7556 - val_mae: 2.5135 - val_accuracy: 0.1380\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.0169 - mae: 2.9190 - accuracy: 0.1249 - val_loss: 17.1654 - val_mae: 2.4797 - val_accuracy: 0.1368\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 22.9503 - mae: 2.8479 - accuracy: 0.1239 - val_loss: 17.3046 - val_mae: 2.5459 - val_accuracy: 0.1376\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 22.8915 - mae: 2.8759 - accuracy: 0.1244 - val_loss: 17.2431 - val_mae: 2.5548 - val_accuracy: 0.1372\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 22.9044 - mae: 2.8451 - accuracy: 0.1255 - val_loss: 15.9289 - val_mae: 2.4357 - val_accuracy: 0.1372\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.2334 - mae: 2.8132 - accuracy: 0.1248 - val_loss: 16.2796 - val_mae: 2.4393 - val_accuracy: 0.1372\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.6739 - mae: 2.7850 - accuracy: 0.1247 - val_loss: 19.0641 - val_mae: 2.6756 - val_accuracy: 0.1364\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.3220 - mae: 2.7614 - accuracy: 0.1235 - val_loss: 15.5977 - val_mae: 2.3974 - val_accuracy: 0.1372\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 21.4318 - mae: 2.7697 - accuracy: 0.1262 - val_loss: 15.3168 - val_mae: 2.4021 - val_accuracy: 0.1372\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.2862 - mae: 2.7488 - accuracy: 0.1245 - val_loss: 15.4497 - val_mae: 2.3633 - val_accuracy: 0.1376\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 20.9784 - mae: 2.7100 - accuracy: 0.1247 - val_loss: 15.8430 - val_mae: 2.3593 - val_accuracy: 0.1372\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 20.6486 - mae: 2.6979 - accuracy: 0.1240 - val_loss: 14.8736 - val_mae: 2.3280 - val_accuracy: 0.1368\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 20.7248 - mae: 2.7074 - accuracy: 0.1246 - val_loss: 14.4708 - val_mae: 2.3436 - val_accuracy: 0.1368\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.0797 - mae: 2.6630 - accuracy: 0.1250 - val_loss: 15.1062 - val_mae: 2.4022 - val_accuracy: 0.1376\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 19.8985 - mae: 2.6634 - accuracy: 0.1259 - val_loss: 14.5351 - val_mae: 2.3040 - val_accuracy: 0.1387\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 19.7047 - mae: 2.6274 - accuracy: 0.1245 - val_loss: 14.2519 - val_mae: 2.3153 - val_accuracy: 0.1387\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 19.6241 - mae: 2.6290 - accuracy: 0.1254 - val_loss: 14.1344 - val_mae: 2.2745 - val_accuracy: 0.1391\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.2794 - mae: 2.6179 - accuracy: 0.1259 - val_loss: 14.0404 - val_mae: 2.3026 - val_accuracy: 0.1395\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.1953 - mae: 2.5993 - accuracy: 0.1243 - val_loss: 13.9164 - val_mae: 2.2904 - val_accuracy: 0.1395\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 18.7295 - mae: 2.5788 - accuracy: 0.1261 - val_loss: 14.0941 - val_mae: 2.2417 - val_accuracy: 0.1399\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.8736 - mae: 2.5707 - accuracy: 0.1249 - val_loss: 13.5375 - val_mae: 2.2302 - val_accuracy: 0.1383\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 19.2974 - mae: 2.5801 - accuracy: 0.1260 - val_loss: 13.5485 - val_mae: 2.2048 - val_accuracy: 0.1391\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.5043 - mae: 2.5479 - accuracy: 0.1253 - val_loss: 13.4025 - val_mae: 2.2174 - val_accuracy: 0.1387\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.5520 - mae: 2.5441 - accuracy: 0.1251 - val_loss: 14.0581 - val_mae: 2.2268 - val_accuracy: 0.1376\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.7317 - mae: 2.5039 - accuracy: 0.1245 - val_loss: 13.5841 - val_mae: 2.2129 - val_accuracy: 0.1395\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 18.0562 - mae: 2.5181 - accuracy: 0.1253 - val_loss: 13.6872 - val_mae: 2.2013 - val_accuracy: 0.1372\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.7691 - mae: 2.4881 - accuracy: 0.1248 - val_loss: 14.3039 - val_mae: 2.2303 - val_accuracy: 0.1387\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.8633 - mae: 2.4995 - accuracy: 0.1248 - val_loss: 13.0339 - val_mae: 2.1989 - val_accuracy: 0.1403\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.3327 - mae: 2.4869 - accuracy: 0.1252 - val_loss: 13.3444 - val_mae: 2.1870 - val_accuracy: 0.1391\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 16.9571 - mae: 2.4673 - accuracy: 0.1254 - val_loss: 12.8716 - val_mae: 2.1851 - val_accuracy: 0.1376\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 17.0558 - mae: 2.4657 - accuracy: 0.1265 - val_loss: 12.9064 - val_mae: 2.1726 - val_accuracy: 0.1387\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.2098 - mae: 2.4572 - accuracy: 0.1253 - val_loss: 12.8954 - val_mae: 2.1743 - val_accuracy: 0.1395\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.6075 - mae: 2.4176 - accuracy: 0.1261 - val_loss: 12.8799 - val_mae: 2.1726 - val_accuracy: 0.1399\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 16.2211 - mae: 2.4076 - accuracy: 0.1249 - val_loss: 12.8144 - val_mae: 2.1700 - val_accuracy: 0.1380\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 2s 14ms/step - loss: 17.1341 - mae: 2.4492 - accuracy: 0.1249 - val_loss: 12.8634 - val_mae: 2.1647 - val_accuracy: 0.1387\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.3442 - mae: 2.3954 - accuracy: 0.1256 - val_loss: 12.5822 - val_mae: 2.1565 - val_accuracy: 0.1380\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.2396 - mae: 2.4046 - accuracy: 0.1255 - val_loss: 12.7385 - val_mae: 2.1773 - val_accuracy: 0.1407\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 16.3826 - mae: 2.3997 - accuracy: 0.1250 - val_loss: 12.5374 - val_mae: 2.1538 - val_accuracy: 0.1387\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 15.8890 - mae: 2.3792 - accuracy: 0.1254 - val_loss: 12.6332 - val_mae: 2.1402 - val_accuracy: 0.1387\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 3s 21ms/step - loss: 15.9174 - mae: 2.3793 - accuracy: 0.1257 - val_loss: 12.4771 - val_mae: 2.1288 - val_accuracy: 0.1383\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 4s 22ms/step - loss: 15.5289 - mae: 2.3482 - accuracy: 0.1247 - val_loss: 12.3810 - val_mae: 2.1349 - val_accuracy: 0.1391\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 15.6435 - mae: 2.3414 - accuracy: 0.1253 - val_loss: 12.5506 - val_mae: 2.1270 - val_accuracy: 0.1383\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 15.8368 - mae: 2.3588 - accuracy: 0.1253 - val_loss: 12.3158 - val_mae: 2.1187 - val_accuracy: 0.1399\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 4s 23ms/step - loss: 15.2976 - mae: 2.3293 - accuracy: 0.1240 - val_loss: 12.6356 - val_mae: 2.1592 - val_accuracy: 0.1403\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 4s 22ms/step - loss: 15.3616 - mae: 2.3218 - accuracy: 0.1249 - val_loss: 12.3583 - val_mae: 2.1305 - val_accuracy: 0.1383\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 14.6759 - mae: 2.3056 - accuracy: 0.1250 - val_loss: 12.3288 - val_mae: 2.1302 - val_accuracy: 0.1395\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 15.2422 - mae: 2.3373 - accuracy: 0.1254 - val_loss: 13.2604 - val_mae: 2.1450 - val_accuracy: 0.1395\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 14.9985 - mae: 2.3037 - accuracy: 0.1257 - val_loss: 12.8403 - val_mae: 2.1722 - val_accuracy: 0.1414\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 3s 21ms/step - loss: 15.2153 - mae: 2.3171 - accuracy: 0.1251 - val_loss: 12.6458 - val_mae: 2.1177 - val_accuracy: 0.1387\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 3s 21ms/step - loss: 14.6916 - mae: 2.2797 - accuracy: 0.1244 - val_loss: 12.7281 - val_mae: 2.1678 - val_accuracy: 0.1410\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 14.5104 - mae: 2.2766 - accuracy: 0.1260 - val_loss: 12.5470 - val_mae: 2.1650 - val_accuracy: 0.1414\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 14.4237 - mae: 2.2844 - accuracy: 0.1252 - val_loss: 12.4868 - val_mae: 2.1013 - val_accuracy: 0.1391\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 14.6215 - mae: 2.2771 - accuracy: 0.1247 - val_loss: 12.2774 - val_mae: 2.1262 - val_accuracy: 0.1414\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 14.4593 - mae: 2.2751 - accuracy: 0.1244 - val_loss: 11.7272 - val_mae: 2.0866 - val_accuracy: 0.1387\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.6616 - mae: 2.2680 - accuracy: 0.1254 - val_loss: 11.9376 - val_mae: 2.1068 - val_accuracy: 0.1407\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.7059 - mae: 2.2621 - accuracy: 0.1252 - val_loss: 11.7840 - val_mae: 2.0996 - val_accuracy: 0.1403\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 14.1783 - mae: 2.2508 - accuracy: 0.1249 - val_loss: 11.7010 - val_mae: 2.0722 - val_accuracy: 0.1407\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 14.2224 - mae: 2.2520 - accuracy: 0.1252 - val_loss: 11.8842 - val_mae: 2.0803 - val_accuracy: 0.1403\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 14.3048 - mae: 2.2573 - accuracy: 0.1246 - val_loss: 12.1491 - val_mae: 2.1250 - val_accuracy: 0.1403\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 14.0140 - mae: 2.2185 - accuracy: 0.1247 - val_loss: 12.3327 - val_mae: 2.0998 - val_accuracy: 0.1407\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 13.8353 - mae: 2.2250 - accuracy: 0.1260 - val_loss: 11.6777 - val_mae: 2.0865 - val_accuracy: 0.1380\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.1114 - mae: 2.2421 - accuracy: 0.1254 - val_loss: 11.5106 - val_mae: 2.0866 - val_accuracy: 0.1399\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 14.0102 - mae: 2.2338 - accuracy: 0.1246 - val_loss: 11.8822 - val_mae: 2.0780 - val_accuracy: 0.1399\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 13.2521 - mae: 2.1954 - accuracy: 0.1247 - val_loss: 11.5995 - val_mae: 2.0736 - val_accuracy: 0.1391\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.7703 - mae: 2.2344 - accuracy: 0.1252 - val_loss: 11.5246 - val_mae: 2.0619 - val_accuracy: 0.1395\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 13.5455 - mae: 2.1956 - accuracy: 0.1261 - val_loss: 11.8327 - val_mae: 2.0666 - val_accuracy: 0.1395\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 13.2775 - mae: 2.1679 - accuracy: 0.1268 - val_loss: 12.0800 - val_mae: 2.1262 - val_accuracy: 0.1407\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.7905 - mae: 2.2033 - accuracy: 0.1252 - val_loss: 11.5866 - val_mae: 2.0645 - val_accuracy: 0.1387\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 13.4338 - mae: 2.1904 - accuracy: 0.1239 - val_loss: 11.4272 - val_mae: 2.0445 - val_accuracy: 0.1395\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 13.6414 - mae: 2.2048 - accuracy: 0.1261 - val_loss: 11.4712 - val_mae: 2.0492 - val_accuracy: 0.1395\n",
      "Kappa Score: 0.9258959375753888\n",
      "\n",
      "--------Fold 5--------\n",
      "\n",
      "WARNING:tensorflow:Layer lstm_150 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "WARNING:tensorflow:Layer lstm_151 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
      "Model: \"sequential_75\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " lstm_150 (LSTM)             (None, 1, 300)            721200    \n",
      "                                                                 \n",
      " lstm_151 (LSTM)             (None, 64)                93440     \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_75 (Dense)            (None, 1)                 65        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 814,705\n",
      "Trainable params: 814,705\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n",
      "163/163 [==============================] - 8s 22ms/step - loss: 81.0650 - mae: 5.2484 - accuracy: 0.1195 - val_loss: 66.7752 - val_mae: 4.8027 - val_accuracy: 0.1318\n",
      "Epoch 2/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 64.4761 - mae: 4.8734 - accuracy: 0.1161 - val_loss: 60.2601 - val_mae: 4.6575 - val_accuracy: 0.1175\n",
      "Epoch 3/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 60.3224 - mae: 4.7705 - accuracy: 0.1075 - val_loss: 55.6810 - val_mae: 4.6331 - val_accuracy: 0.1102\n",
      "Epoch 4/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 57.2574 - mae: 4.7406 - accuracy: 0.1038 - val_loss: 52.8236 - val_mae: 4.3655 - val_accuracy: 0.1025\n",
      "Epoch 5/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 55.9984 - mae: 4.6947 - accuracy: 0.1008 - val_loss: 50.1743 - val_mae: 4.3873 - val_accuracy: 0.1075\n",
      "Epoch 6/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 54.0514 - mae: 4.6351 - accuracy: 0.1014 - val_loss: 48.4848 - val_mae: 4.4139 - val_accuracy: 0.1083\n",
      "Epoch 7/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 52.6708 - mae: 4.6039 - accuracy: 0.1022 - val_loss: 45.2956 - val_mae: 4.0923 - val_accuracy: 0.1052\n",
      "Epoch 8/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 52.2536 - mae: 4.5684 - accuracy: 0.1026 - val_loss: 43.6173 - val_mae: 4.1182 - val_accuracy: 0.1133\n",
      "Epoch 9/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 49.6815 - mae: 4.4515 - accuracy: 0.1040 - val_loss: 41.3493 - val_mae: 3.8515 - val_accuracy: 0.1094\n",
      "Epoch 10/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 47.9448 - mae: 4.3616 - accuracy: 0.1062 - val_loss: 39.6534 - val_mae: 3.8542 - val_accuracy: 0.1133\n",
      "Epoch 11/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 46.2433 - mae: 4.2688 - accuracy: 0.1086 - val_loss: 40.1760 - val_mae: 3.6917 - val_accuracy: 0.1168\n",
      "Epoch 12/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 45.5812 - mae: 4.2191 - accuracy: 0.1151 - val_loss: 38.1111 - val_mae: 3.6928 - val_accuracy: 0.1175\n",
      "Epoch 13/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 43.0659 - mae: 4.0543 - accuracy: 0.1189 - val_loss: 35.6838 - val_mae: 3.6786 - val_accuracy: 0.1198\n",
      "Epoch 14/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 42.2290 - mae: 4.0318 - accuracy: 0.1172 - val_loss: 34.9908 - val_mae: 3.5505 - val_accuracy: 0.1202\n",
      "Epoch 15/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 39.2741 - mae: 3.8887 - accuracy: 0.1185 - val_loss: 33.2788 - val_mae: 3.4920 - val_accuracy: 0.1195\n",
      "Epoch 16/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 38.8611 - mae: 3.8436 - accuracy: 0.1212 - val_loss: 34.2850 - val_mae: 3.4467 - val_accuracy: 0.1214\n",
      "Epoch 17/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 37.6658 - mae: 3.7711 - accuracy: 0.1215 - val_loss: 33.0822 - val_mae: 3.3694 - val_accuracy: 0.1195\n",
      "Epoch 18/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 35.9676 - mae: 3.6866 - accuracy: 0.1205 - val_loss: 31.0666 - val_mae: 3.3098 - val_accuracy: 0.1210\n",
      "Epoch 19/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 34.6426 - mae: 3.6375 - accuracy: 0.1197 - val_loss: 30.5623 - val_mae: 3.2530 - val_accuracy: 0.1222\n",
      "Epoch 20/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 33.7585 - mae: 3.5800 - accuracy: 0.1215 - val_loss: 28.6695 - val_mae: 3.2165 - val_accuracy: 0.1229\n",
      "Epoch 21/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 32.9706 - mae: 3.5228 - accuracy: 0.1221 - val_loss: 27.6697 - val_mae: 3.1889 - val_accuracy: 0.1233\n",
      "Epoch 22/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 31.4982 - mae: 3.4371 - accuracy: 0.1221 - val_loss: 26.5418 - val_mae: 3.1567 - val_accuracy: 0.1245\n",
      "Epoch 23/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 31.3056 - mae: 3.4008 - accuracy: 0.1235 - val_loss: 26.7118 - val_mae: 3.1165 - val_accuracy: 0.1279\n",
      "Epoch 24/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 30.9882 - mae: 3.4009 - accuracy: 0.1226 - val_loss: 26.1029 - val_mae: 3.0947 - val_accuracy: 0.1283\n",
      "Epoch 25/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 29.8441 - mae: 3.3368 - accuracy: 0.1237 - val_loss: 26.4961 - val_mae: 3.0627 - val_accuracy: 0.1283\n",
      "Epoch 26/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 29.6396 - mae: 3.3080 - accuracy: 0.1249 - val_loss: 24.7987 - val_mae: 3.1070 - val_accuracy: 0.1276\n",
      "Epoch 27/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 28.7614 - mae: 3.2668 - accuracy: 0.1223 - val_loss: 24.2300 - val_mae: 3.0727 - val_accuracy: 0.1287\n",
      "Epoch 28/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 28.2324 - mae: 3.2303 - accuracy: 0.1238 - val_loss: 27.1100 - val_mae: 3.0387 - val_accuracy: 0.1279\n",
      "Epoch 29/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 28.4830 - mae: 3.2420 - accuracy: 0.1212 - val_loss: 24.6643 - val_mae: 2.9728 - val_accuracy: 0.1295\n",
      "Epoch 30/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 27.4501 - mae: 3.1933 - accuracy: 0.1228 - val_loss: 23.6202 - val_mae: 2.9706 - val_accuracy: 0.1291\n",
      "Epoch 31/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 27.1116 - mae: 3.1496 - accuracy: 0.1215 - val_loss: 24.0727 - val_mae: 2.9504 - val_accuracy: 0.1310\n",
      "Epoch 32/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 26.4132 - mae: 3.1130 - accuracy: 0.1240 - val_loss: 23.2724 - val_mae: 2.9746 - val_accuracy: 0.1306\n",
      "Epoch 33/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 26.4845 - mae: 3.1208 - accuracy: 0.1246 - val_loss: 22.8143 - val_mae: 2.9023 - val_accuracy: 0.1299\n",
      "Epoch 34/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 25.3522 - mae: 3.0558 - accuracy: 0.1250 - val_loss: 22.6337 - val_mae: 2.8987 - val_accuracy: 0.1306\n",
      "Epoch 35/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 25.6121 - mae: 3.0579 - accuracy: 0.1241 - val_loss: 22.0975 - val_mae: 2.9182 - val_accuracy: 0.1310\n",
      "Epoch 36/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 25.6925 - mae: 3.0548 - accuracy: 0.1247 - val_loss: 24.0031 - val_mae: 2.8797 - val_accuracy: 0.1306\n",
      "Epoch 37/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 24.9684 - mae: 3.0189 - accuracy: 0.1271 - val_loss: 23.1130 - val_mae: 2.8635 - val_accuracy: 0.1314\n",
      "Epoch 38/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 24.4442 - mae: 2.9933 - accuracy: 0.1241 - val_loss: 21.3246 - val_mae: 2.9141 - val_accuracy: 0.1306\n",
      "Epoch 39/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 23.7264 - mae: 2.9646 - accuracy: 0.1261 - val_loss: 20.7523 - val_mae: 2.8410 - val_accuracy: 0.1306\n",
      "Epoch 40/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 23.6346 - mae: 2.9568 - accuracy: 0.1256 - val_loss: 21.8205 - val_mae: 2.8130 - val_accuracy: 0.1322\n",
      "Epoch 41/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 23.7816 - mae: 2.9443 - accuracy: 0.1239 - val_loss: 21.0480 - val_mae: 2.8193 - val_accuracy: 0.1326\n",
      "Epoch 42/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 24.1449 - mae: 2.9591 - accuracy: 0.1241 - val_loss: 21.7404 - val_mae: 2.8121 - val_accuracy: 0.1314\n",
      "Epoch 43/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 23.4160 - mae: 2.9201 - accuracy: 0.1253 - val_loss: 21.3133 - val_mae: 2.7867 - val_accuracy: 0.1329\n",
      "Epoch 44/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 23.8243 - mae: 2.8982 - accuracy: 0.1263 - val_loss: 20.3959 - val_mae: 2.7833 - val_accuracy: 0.1329\n",
      "Epoch 45/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.6176 - mae: 2.8762 - accuracy: 0.1251 - val_loss: 20.4264 - val_mae: 2.7776 - val_accuracy: 0.1329\n",
      "Epoch 46/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.6428 - mae: 2.8559 - accuracy: 0.1259 - val_loss: 20.4315 - val_mae: 2.8114 - val_accuracy: 0.1326\n",
      "Epoch 47/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 22.0920 - mae: 2.8437 - accuracy: 0.1241 - val_loss: 19.3890 - val_mae: 2.7653 - val_accuracy: 0.1333\n",
      "Epoch 48/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.5330 - mae: 2.8231 - accuracy: 0.1262 - val_loss: 20.1263 - val_mae: 2.7422 - val_accuracy: 0.1333\n",
      "Epoch 49/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 22.3723 - mae: 2.8424 - accuracy: 0.1254 - val_loss: 19.7425 - val_mae: 2.6926 - val_accuracy: 0.1333\n",
      "Epoch 50/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 21.8148 - mae: 2.8071 - accuracy: 0.1275 - val_loss: 20.7382 - val_mae: 2.6995 - val_accuracy: 0.1349\n",
      "Epoch 51/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 22.3534 - mae: 2.8451 - accuracy: 0.1272 - val_loss: 18.8235 - val_mae: 2.6765 - val_accuracy: 0.1345\n",
      "Epoch 52/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.2053 - mae: 2.7614 - accuracy: 0.1264 - val_loss: 19.3587 - val_mae: 2.7669 - val_accuracy: 0.1353\n",
      "Epoch 53/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 20.8745 - mae: 2.7540 - accuracy: 0.1276 - val_loss: 18.7367 - val_mae: 2.6474 - val_accuracy: 0.1356\n",
      "Epoch 54/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 21.5506 - mae: 2.7840 - accuracy: 0.1271 - val_loss: 18.4724 - val_mae: 2.6560 - val_accuracy: 0.1360\n",
      "Epoch 55/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 21.5308 - mae: 2.7905 - accuracy: 0.1278 - val_loss: 18.6108 - val_mae: 2.6511 - val_accuracy: 0.1360\n",
      "Epoch 56/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 21.5046 - mae: 2.7596 - accuracy: 0.1261 - val_loss: 18.4870 - val_mae: 2.6681 - val_accuracy: 0.1353\n",
      "Epoch 57/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 20.6738 - mae: 2.7245 - accuracy: 0.1254 - val_loss: 18.3861 - val_mae: 2.6586 - val_accuracy: 0.1356\n",
      "Epoch 58/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 20.3496 - mae: 2.7281 - accuracy: 0.1272 - val_loss: 18.2456 - val_mae: 2.6451 - val_accuracy: 0.1356\n",
      "Epoch 59/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 21.1375 - mae: 2.7498 - accuracy: 0.1275 - val_loss: 18.7725 - val_mae: 2.6473 - val_accuracy: 0.1364\n",
      "Epoch 60/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 20.7410 - mae: 2.7267 - accuracy: 0.1260 - val_loss: 18.8872 - val_mae: 2.7109 - val_accuracy: 0.1356\n",
      "Epoch 61/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 20.4907 - mae: 2.7176 - accuracy: 0.1255 - val_loss: 19.4781 - val_mae: 2.6258 - val_accuracy: 0.1356\n",
      "Epoch 62/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 20.8504 - mae: 2.7163 - accuracy: 0.1247 - val_loss: 19.7151 - val_mae: 2.6416 - val_accuracy: 0.1360\n",
      "Epoch 63/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 20.1462 - mae: 2.6988 - accuracy: 0.1259 - val_loss: 18.3600 - val_mae: 2.6233 - val_accuracy: 0.1356\n",
      "Epoch 64/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 19.5429 - mae: 2.6596 - accuracy: 0.1261 - val_loss: 18.2031 - val_mae: 2.6150 - val_accuracy: 0.1345\n",
      "Epoch 65/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 20.0075 - mae: 2.6812 - accuracy: 0.1265 - val_loss: 20.5168 - val_mae: 2.6380 - val_accuracy: 0.1368\n",
      "Epoch 66/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 19.8115 - mae: 2.6523 - accuracy: 0.1272 - val_loss: 18.6129 - val_mae: 2.5901 - val_accuracy: 0.1360\n",
      "Epoch 67/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 19.4495 - mae: 2.6501 - accuracy: 0.1281 - val_loss: 18.0680 - val_mae: 2.5803 - val_accuracy: 0.1360\n",
      "Epoch 68/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 20.1073 - mae: 2.6902 - accuracy: 0.1271 - val_loss: 18.0429 - val_mae: 2.6126 - val_accuracy: 0.1368\n",
      "Epoch 69/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 19.5170 - mae: 2.6668 - accuracy: 0.1263 - val_loss: 18.6656 - val_mae: 2.5720 - val_accuracy: 0.1364\n",
      "Epoch 70/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 19.1118 - mae: 2.6489 - accuracy: 0.1280 - val_loss: 18.5262 - val_mae: 2.5687 - val_accuracy: 0.1364\n",
      "Epoch 71/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 18.8726 - mae: 2.6169 - accuracy: 0.1278 - val_loss: 17.4879 - val_mae: 2.5479 - val_accuracy: 0.1364\n",
      "Epoch 72/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 19.4980 - mae: 2.6425 - accuracy: 0.1275 - val_loss: 17.4644 - val_mae: 2.5445 - val_accuracy: 0.1368\n",
      "Epoch 73/100\n",
      "163/163 [==============================] - 3s 20ms/step - loss: 19.4916 - mae: 2.6391 - accuracy: 0.1280 - val_loss: 19.7127 - val_mae: 2.5908 - val_accuracy: 0.1368\n",
      "Epoch 74/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 18.6257 - mae: 2.6001 - accuracy: 0.1280 - val_loss: 17.7015 - val_mae: 2.6204 - val_accuracy: 0.1372\n",
      "Epoch 75/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.3853 - mae: 2.5899 - accuracy: 0.1258 - val_loss: 18.2340 - val_mae: 2.5414 - val_accuracy: 0.1368\n",
      "Epoch 76/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 19.0087 - mae: 2.6006 - accuracy: 0.1267 - val_loss: 17.7377 - val_mae: 2.6467 - val_accuracy: 0.1368\n",
      "Epoch 77/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.8211 - mae: 2.6038 - accuracy: 0.1275 - val_loss: 17.2173 - val_mae: 2.5343 - val_accuracy: 0.1368\n",
      "Epoch 78/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 18.9914 - mae: 2.5977 - accuracy: 0.1258 - val_loss: 16.9406 - val_mae: 2.5104 - val_accuracy: 0.1368\n",
      "Epoch 79/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.8302 - mae: 2.6010 - accuracy: 0.1281 - val_loss: 17.6581 - val_mae: 2.5111 - val_accuracy: 0.1368\n",
      "Epoch 80/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 18.0983 - mae: 2.5676 - accuracy: 0.1281 - val_loss: 17.7697 - val_mae: 2.5262 - val_accuracy: 0.1368\n",
      "Epoch 81/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 18.8965 - mae: 2.5880 - accuracy: 0.1268 - val_loss: 17.1192 - val_mae: 2.4987 - val_accuracy: 0.1368\n",
      "Epoch 82/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 18.3740 - mae: 2.5812 - accuracy: 0.1273 - val_loss: 16.9889 - val_mae: 2.4811 - val_accuracy: 0.1368\n",
      "Epoch 83/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.1225 - mae: 2.5465 - accuracy: 0.1277 - val_loss: 16.8551 - val_mae: 2.5232 - val_accuracy: 0.1372\n",
      "Epoch 84/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 18.1100 - mae: 2.5428 - accuracy: 0.1279 - val_loss: 17.9766 - val_mae: 2.5023 - val_accuracy: 0.1368\n",
      "Epoch 85/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.8503 - mae: 2.5331 - accuracy: 0.1277 - val_loss: 17.8321 - val_mae: 2.5076 - val_accuracy: 0.1372\n",
      "Epoch 86/100\n",
      "163/163 [==============================] - 3s 19ms/step - loss: 18.1918 - mae: 2.5342 - accuracy: 0.1286 - val_loss: 16.7439 - val_mae: 2.5025 - val_accuracy: 0.1368\n",
      "Epoch 87/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 18.4243 - mae: 2.5535 - accuracy: 0.1283 - val_loss: 17.0360 - val_mae: 2.4995 - val_accuracy: 0.1368\n",
      "Epoch 88/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.3527 - mae: 2.5541 - accuracy: 0.1273 - val_loss: 16.9934 - val_mae: 2.5641 - val_accuracy: 0.1368\n",
      "Epoch 89/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 18.4219 - mae: 2.5571 - accuracy: 0.1273 - val_loss: 17.2760 - val_mae: 2.4934 - val_accuracy: 0.1368\n",
      "Epoch 90/100\n",
      "163/163 [==============================] - 3s 15ms/step - loss: 17.4321 - mae: 2.5188 - accuracy: 0.1290 - val_loss: 16.9041 - val_mae: 2.4973 - val_accuracy: 0.1368\n",
      "Epoch 91/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 17.6257 - mae: 2.5197 - accuracy: 0.1284 - val_loss: 17.0213 - val_mae: 2.4534 - val_accuracy: 0.1372\n",
      "Epoch 92/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 17.4492 - mae: 2.5039 - accuracy: 0.1294 - val_loss: 18.5197 - val_mae: 2.5088 - val_accuracy: 0.1368\n",
      "Epoch 93/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.7962 - mae: 2.4879 - accuracy: 0.1271 - val_loss: 16.3303 - val_mae: 2.4262 - val_accuracy: 0.1368\n",
      "Epoch 94/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 17.9810 - mae: 2.5302 - accuracy: 0.1280 - val_loss: 16.6972 - val_mae: 2.4645 - val_accuracy: 0.1372\n",
      "Epoch 95/100\n",
      "163/163 [==============================] - 3s 16ms/step - loss: 16.8130 - mae: 2.4713 - accuracy: 0.1287 - val_loss: 16.9445 - val_mae: 2.5214 - val_accuracy: 0.1368\n",
      "Epoch 96/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 17.2429 - mae: 2.4766 - accuracy: 0.1271 - val_loss: 18.7301 - val_mae: 2.4922 - val_accuracy: 0.1372\n",
      "Epoch 97/100\n",
      "163/163 [==============================] - 2s 15ms/step - loss: 17.1867 - mae: 2.4795 - accuracy: 0.1274 - val_loss: 17.3846 - val_mae: 2.4514 - val_accuracy: 0.1372\n",
      "Epoch 98/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 17.6527 - mae: 2.4931 - accuracy: 0.1277 - val_loss: 17.4506 - val_mae: 2.4494 - val_accuracy: 0.1372\n",
      "Epoch 99/100\n",
      "163/163 [==============================] - 3s 17ms/step - loss: 17.3057 - mae: 2.4808 - accuracy: 0.1273 - val_loss: 16.3502 - val_mae: 2.4167 - val_accuracy: 0.1345\n",
      "Epoch 100/100\n",
      "163/163 [==============================] - 3s 18ms/step - loss: 17.5851 - mae: 2.4834 - accuracy: 0.1280 - val_loss: 16.2320 - val_mae: 2.4351 - val_accuracy: 0.1368\n",
      "Kappa Score: 0.884601576185775\n"
     ]
    }
   ],
   "source": [
    "cv = KFold(n_splits=5, shuffle=True)\n",
    "results = []\n",
    "\n",
    "count = 1\n",
    "for train_idx, test_idx in cv.split(X):\n",
    "    print(\"\\n--------Fold {}--------\\n\".format(count))\n",
    "    X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
    "    y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
    "\n",
    "    train_essays = X_train['essay']\n",
    "    test_essays = X_test['essay']\n",
    "\n",
    "    sentences = []\n",
    "    sentences_test = []\n",
    "    clean_train_essays = []\n",
    "    clean_test_essays = []\n",
    "    for essay in train_essays:\n",
    "        sentences += sentences_from_essay(essay, remove_stopwords=True)\n",
    "    for test_essay in test_essays:\n",
    "        sentences_test += sentences_from_essay(test_essay, remove_stopwords=True)\n",
    "    for essay_v in train_essays:\n",
    "        clean_train_essays.append(wordlist_from_essay(essay_v, remove_stopwords=True))\n",
    "    for test_essay in test_essays:\n",
    "        clean_test_essays.append(wordlist_from_essay(test_essay, remove_stopwords=True))\n",
    "\n",
    "    num_features = 300\n",
    "    min_word_count = 40\n",
    "    num_workers = 8\n",
    "    context = 10\n",
    "    downsampling = 1e-3\n",
    "\n",
    "    model = Word2Vec(sentences, workers=num_workers, vector_size=num_features, min_count=min_word_count, window=context, sample=downsampling)\n",
    "\n",
    "    model.init_sims(replace=True)\n",
    "    model.wv.save_word2vec_format('word2vecmodel.bin', binary=True)\n",
    "\n",
    "    trainDataVecs = getAvgFeatureVecs(clean_train_essays, model, num_features)\n",
    "    testDataVecs = getAvgFeatureVecs(clean_test_essays, model, num_features)\n",
    "    clean_test_essays = []\n",
    "    for essay_v in test_essays:\n",
    "        clean_test_essays.append(wordlist_from_essay(essay_v, remove_stopwords=True))\n",
    "    testDataVecs = getAvgFeatureVecs(clean_test_essays, model, num_features)\n",
    "\n",
    "    trainDataVecs = np.array(trainDataVecs)\n",
    "    testDataVecs = np.array(testDataVecs)\n",
    "    # Reshaping train and test vectors to 3 dimensions. (1 represents one timestep)\n",
    "    trainDataVecs = np.reshape(trainDataVecs, (trainDataVecs.shape[0], 1, trainDataVecs.shape[1]))\n",
    "    testDataVecs = np.reshape(testDataVecs, (testDataVecs.shape[0], 1, testDataVecs.shape[1]))\n",
    "\n",
    "    lstm_model = get_model()\n",
    "    history = lstm_model.fit(trainDataVecs, y_train, batch_size=64, epochs=100, validation_data=(testDataVecs, y_test))\n",
    "\n",
    "    y_pred = lstm_model.predict(testDataVecs)\n",
    "\n",
    "    # Save any one of the 5 models.\n",
    "    if count == 5:\n",
    "         lstm_model.save_weights('final_lstm.h5')\n",
    "\n",
    "    # Round y_pred to the nearest integer.\n",
    "    y_pred = np.around(y_pred)\n",
    "\n",
    "    # Evaluate the model on the evaluation metric. \"Quadratic mean averaged Kappa\"\n",
    "    result = cohen_kappa_score(y_test.values, y_pred, weights='quadratic')\n",
    "    print(\"Kappa Score: {}\".format(result))\n",
    "    results.append(result)\n",
    "\n",
    "    count += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Model Evaluation:\n",
    "\n",
    " - It seems that the model has a good performance, with an average Kappa score of 0.91. This means that the model has a high level of agreement with the human graders in assessing the quality of the essay answers. It also indicates that the model is able to generalize well to new data, as the cross-validation approach ensures that the model is tested on different subsets of the data. Overall, this is a promising result that suggests that the model can be used to grade essays in an automated and efficient way.\n",
    "\n",
    "- We can also see that the training loss and the testing loss is following the same trend and it is going down each epochs but at the end of the curve it is flattening out which means the model woult not perform better even if we increase epochs\n",
    "\n",
    "- We can also see that the mean absolute error and the testing mean absolute error and both is following the downwards trend and won't perform better even if we increase epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the training and testing loss\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Testing Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Plot the training and testing accuracy\n",
    "plt.plot(history.history['mae'], label='Mean Absolute Error')\n",
    "plt.plot(history.history['val_mae'], label=' Testing MEan Absolute Error')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('MAE')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Kappa score after a 5-fold cross validation:  0.9109\n"
     ]
    }
   ],
   "source": [
    "print(\"Average Kappa score after a 5-fold cross validation: \",np.around(np.array(results).mean(),decimals=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear local newspaper, I think effects computer...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @CAPS1 @CAPS2, I believe that using compu...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear Local Newspaper, @CAPS1 I have found that...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>Dear @LOCATION1, I know having computers has a...</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   essay_id  essay_set                                              essay  \\\n",
       "0         1          1  Dear local newspaper, I think effects computer...   \n",
       "1         2          1  Dear @CAPS1 @CAPS2, I believe that using compu...   \n",
       "2         3          1  Dear, @CAPS1 @CAPS2 @CAPS3 More and more peopl...   \n",
       "3         4          1  Dear Local Newspaper, @CAPS1 I have found that...   \n",
       "4         5          1  Dear @LOCATION1, I know having computers has a...   \n",
       "\n",
       "   domain1_score  \n",
       "0              8  \n",
       "1              9  \n",
       "2              7  \n",
       "3             10  \n",
       "4              8  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>essay_id</th>\n",
       "      <th>essay_set</th>\n",
       "      <th>essay</th>\n",
       "      <th>domain1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12971</th>\n",
       "      <td>21626</td>\n",
       "      <td>8</td>\n",
       "      <td>In most stories mothers and daughters are eit...</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12972</th>\n",
       "      <td>21628</td>\n",
       "      <td>8</td>\n",
       "      <td>I never understood the meaning laughter is th...</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12973</th>\n",
       "      <td>21629</td>\n",
       "      <td>8</td>\n",
       "      <td>When you laugh, is @CAPS5 out of habit, or is ...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12974</th>\n",
       "      <td>21630</td>\n",
       "      <td>8</td>\n",
       "      <td>Trippin' on fen...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12975</th>\n",
       "      <td>21633</td>\n",
       "      <td>8</td>\n",
       "      <td>Many people believe that laughter can improve...</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       essay_id  essay_set                                              essay  \\\n",
       "12971     21626          8   In most stories mothers and daughters are eit...   \n",
       "12972     21628          8   I never understood the meaning laughter is th...   \n",
       "12973     21629          8  When you laugh, is @CAPS5 out of habit, or is ...   \n",
       "12974     21630          8                                 Trippin' on fen...   \n",
       "12975     21633          8   Many people believe that laughter can improve...   \n",
       "\n",
       "       domain1_score  \n",
       "12971             35  \n",
       "12972             32  \n",
       "12973             40  \n",
       "12974             40  \n",
       "12975             40  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues / Improvements\n",
    "\n",
    "- We can used SBERT model for further adding context\n",
    "- We can also create a taxonomy that can further add semantic context\n",
    "- We can add semantic context match to furhter enhance model performance"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References:\n",
    "\n",
    "Dataset 1 - https://rajpurkar.github.io/SQuAD-explorer/ <br>\n",
    "Dataset 2 - https://www.kaggle.com/competitions/asap-sas/data  <br>\n",
    "https://huggingface.co/docs/transformers/tasks/question_answering <br>\n",
    "https://github.com/alexaapo/BERT-based-pretrained-model-using-SQuAD-2.0-dataset <br>\n",
    "r-net.pdf (microsoft.com) \n",
    "Research Paper: https://ieeexplore.ieee.org/document/9002048 <br>\n",
    "Research Paper2: https://ieeexplore.ieee.org/document/9316110 <br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credits\n",
    "\n",
    "**We have used the following dataset https://www.kaggle.com/competitions/asap-aes**\n",
    "It is based on my extension of my research paper https://ieeexplore.ieee.org/document/9002048 which talks about the intial base algorithm we created. \n",
    "Based on the NLP and deep Learning We have extended below and added deep learning techniques learned through this course."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "papermill": {
   "duration": 1162.588092,
   "end_time": "2021-04-11T01:59:05.843016",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-04-11T01:39:43.254924",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
